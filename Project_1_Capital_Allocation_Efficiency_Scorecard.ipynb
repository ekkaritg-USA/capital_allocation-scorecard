{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# =============================================================================\n",
        "#\n",
        "#  CAPITAL ALLOCATION EFFICIENCY SCORECARD\n",
        "#  Magnificent 7 AI-Related CapEx Analysis (FY2022-2024)\n",
        "#\n",
        "#  Author: Ekkarit Gaewprapun, DBA, CMA, FMVA\n",
        "#  Version: 1.0\n",
        "#\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "# Capital Allocation Efficiency Scorecard\n",
        "## Magnificent 7 AI-Related CapEx Analysis (FY2022-2024)\n",
        "\n",
        "**Author**: Ekkarit Gaewprapun, DBA, CMA, FMVA\n",
        "**Last Updated**: [Date]\n",
        "**Version**: 1.0\n",
        "\n",
        "---\n",
        "\n",
        "### Executive Summary\n",
        "\n",
        "This notebook implements a four-dimension scoring framework to evaluate\n",
        "how efficiently the Magnificent Seven technology companies convert\n",
        "AI-related capital expenditure into sustainable financial returns.\n",
        "\n",
        "### Key Findings (FY2024)\n",
        "\n",
        "[Auto-generated summary will appear here after model runs]\n",
        "\n",
        "### Methodology Overview\n",
        "\n",
        "The scorecard evaluates companies across four dimensions:\n",
        "1. **Capital Deployment Scale** — Magnitude and trajectory of investment\n",
        "2. **Conversion Efficiency** — Speed of capital-to-revenue translation\n",
        "3. **Return Quality** — Margin preservation during scaling\n",
        "4. **Sustainability & Risk** — Capacity to maintain investment intensity\n",
        "\n",
        "### Data Sources\n",
        "\n",
        "- SEC 10-K filings (FY2022, FY2023, FY2024)\n",
        "- Earnings call transcripts (FY2025 guidance)\n",
        "- Company segment disclosures\n",
        "\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# DATA VALIDATION SCRIPT\n",
        "# Capital Allocation Efficiency Scorecard\n",
        "# Run this BEFORE executing the main notebook\n",
        "# ============================================================================\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "DATA_PATH = '/content/drive/MyDrive/Projects/CapEx_Scorecard/data/'\n",
        "\n",
        "# Expected schemas\n",
        "EXPECTED_FILES = {\n",
        "    'consolidated_financials.csv': {\n",
        "        'expected_rows': 21,\n",
        "        'required_columns': ['ticker', 'fiscal_year', 'revenue', 'cost_of_revenue',\n",
        "                            'gross_profit', 'rd_expense', 'operating_income', 'net_income',\n",
        "                            'total_assets', 'total_debt', 'cash_and_equivalents',\n",
        "                            'operating_cash_flow', 'capex', 'depreciation_amortization']\n",
        "    },\n",
        "    'segment_financials.csv': {\n",
        "        'expected_rows': 48,\n",
        "        'required_columns': ['ticker', 'fiscal_year', 'segment_name',\n",
        "                            'segment_revenue', 'segment_operating_income']\n",
        "    },\n",
        "    'forward_guidance.csv': {\n",
        "        'expected_rows': 7,\n",
        "        'required_columns': ['ticker', 'guidance_year', 'capex_guidance_low',\n",
        "                            'capex_guidance_high', 'capex_guidance_midpoint',\n",
        "                            'source', 'source_date']\n",
        "    },\n",
        "    'purchase_obligations.csv': {\n",
        "        'expected_rows': 21,\n",
        "        'required_columns': ['ticker', 'fiscal_year', 'purchase_obligations_total',\n",
        "                            'purchase_obligations_1yr', 'operating_lease_obligations',\n",
        "                            'finance_lease_obligations']\n",
        "    }\n",
        "}\n",
        "\n",
        "EXPECTED_COMPANIES = ['AAPL', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
        "EXPECTED_YEARS = [2022, 2023, 2024]\n",
        "\n",
        "# ============================================================================\n",
        "# VALIDATION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def validate_file_exists(filename):\n",
        "    \"\"\"Check if file exists and return DataFrame if so.\"\"\"\n",
        "    filepath = DATA_PATH + filename\n",
        "    if os.path.exists(filepath):\n",
        "        df = pd.read_csv(filepath)\n",
        "        return True, df\n",
        "    return False, None\n",
        "\n",
        "def validate_columns(df, required_columns, filename):\n",
        "    \"\"\"Check for missing columns.\"\"\"\n",
        "    missing = [col for col in required_columns if col not in df.columns]\n",
        "    extra = [col for col in df.columns if col not in required_columns]\n",
        "    return missing, extra\n",
        "\n",
        "def validate_row_count(df, expected_rows):\n",
        "    \"\"\"Check row count.\"\"\"\n",
        "    return len(df), expected_rows, len(df) == expected_rows\n",
        "\n",
        "def validate_companies(df):\n",
        "    \"\"\"Check all expected companies are present.\"\"\"\n",
        "    present = df['ticker'].unique().tolist()\n",
        "    missing = [c for c in EXPECTED_COMPANIES if c not in present]\n",
        "    extra = [c for c in present if c not in EXPECTED_COMPANIES]\n",
        "    return missing, extra\n",
        "\n",
        "def validate_years(df):\n",
        "    \"\"\"Check all expected years are present.\"\"\"\n",
        "    present = df['fiscal_year'].unique().tolist()\n",
        "    missing = [y for y in EXPECTED_YEARS if y not in present]\n",
        "    return missing\n",
        "\n",
        "# ============================================================================\n",
        "# RUN VALIDATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DATA VALIDATION REPORT\")\n",
        "print(\"Capital Allocation Efficiency Scorecard\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "errors = []\n",
        "warnings = []\n",
        "dataframes = {}\n",
        "\n",
        "# Step 1: Check all files exist\n",
        "print(\"\\n1. FILE EXISTENCE CHECK\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for filename in EXPECTED_FILES.keys():\n",
        "    exists, df = validate_file_exists(filename)\n",
        "    if exists:\n",
        "        print(f\"✓ {filename}\")\n",
        "        dataframes[filename] = df\n",
        "    else:\n",
        "        print(f\"✗ MISSING: {filename}\")\n",
        "        errors.append(f\"File not found: {filename}\")\n",
        "\n",
        "# Step 2: Validate columns\n",
        "print(\"\\n2. COLUMN VALIDATION\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for filename, schema in EXPECTED_FILES.items():\n",
        "    if filename in dataframes:\n",
        "        df = dataframes[filename]\n",
        "        missing, extra = validate_columns(df, schema['required_columns'], filename)\n",
        "        if missing:\n",
        "            print(f\"✗ {filename}: Missing columns: {missing}\")\n",
        "            errors.append(f\"{filename} missing columns: {missing}\")\n",
        "        elif extra:\n",
        "            print(f\"⚠ {filename}: Extra columns (ignored): {extra}\")\n",
        "            warnings.append(f\"{filename} has extra columns: {extra}\")\n",
        "        else:\n",
        "            print(f\"✓ {filename}: All columns present\")\n",
        "\n",
        "# Step 3: Validate row counts\n",
        "print(\"\\n3. ROW COUNT VALIDATION\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for filename, schema in EXPECTED_FILES.items():\n",
        "    if filename in dataframes:\n",
        "        df = dataframes[filename]\n",
        "        actual, expected, match = validate_row_count(df, schema['expected_rows'])\n",
        "        if match:\n",
        "            print(f\"✓ {filename}: {actual} rows (expected {expected})\")\n",
        "        else:\n",
        "            print(f\"⚠ {filename}: {actual} rows (expected {expected})\")\n",
        "            if actual < expected:\n",
        "                warnings.append(f\"{filename}: Only {actual} rows, expected {expected}\")\n",
        "\n",
        "# Step 4: Validate companies\n",
        "print(\"\\n4. COMPANY COVERAGE\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for filename in ['consolidated_financials.csv', 'segment_financials.csv', 'purchase_obligations.csv']:\n",
        "    if filename in dataframes:\n",
        "        df = dataframes[filename]\n",
        "        missing, extra = validate_companies(df)\n",
        "        if missing:\n",
        "            print(f\"✗ {filename}: Missing companies: {missing}\")\n",
        "            errors.append(f\"{filename} missing companies: {missing}\")\n",
        "        else:\n",
        "            print(f\"✓ {filename}: All 7 companies present\")\n",
        "\n",
        "# Step 5: Validate years\n",
        "print(\"\\n5. FISCAL YEAR COVERAGE\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for filename in ['consolidated_financials.csv', 'segment_financials.csv', 'purchase_obligations.csv']:\n",
        "    if filename in dataframes:\n",
        "        df = dataframes[filename]\n",
        "        missing = validate_years(df)\n",
        "        if missing:\n",
        "            print(f\"✗ {filename}: Missing years: {missing}\")\n",
        "            errors.append(f\"{filename} missing years: {missing}\")\n",
        "        else:\n",
        "            print(f\"✓ {filename}: All 3 years present (2022-2024)\")\n",
        "\n",
        "# Step 6: Cross-reference segment revenue to consolidated\n",
        "print(\"\\n6. SEGMENT-TO-CONSOLIDATED RECONCILIATION\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "if 'consolidated_financials.csv' in dataframes and 'segment_financials.csv' in dataframes:\n",
        "    consol = dataframes['consolidated_financials.csv']\n",
        "    segments = dataframes['segment_financials.csv']\n",
        "\n",
        "    # Sum segment revenue by company-year\n",
        "    seg_sum = segments.groupby(['ticker', 'fiscal_year'])['segment_revenue'].sum().reset_index()\n",
        "    seg_sum.columns = ['ticker', 'fiscal_year', 'segment_total']\n",
        "\n",
        "    # Merge with consolidated\n",
        "    merged = consol[['ticker', 'fiscal_year', 'revenue']].merge(seg_sum, on=['ticker', 'fiscal_year'], how='left')\n",
        "    merged['diff_pct'] = abs(merged['segment_total'] - merged['revenue']) / merged['revenue'] * 100\n",
        "\n",
        "    print(f\"{'Ticker':<8} {'Year':<6} {'Consol Rev':>14} {'Seg Sum':>14} {'Diff %':>8} {'Status':<10}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for _, row in merged[merged['fiscal_year'] == 2024].iterrows():\n",
        "        diff_pct = row['diff_pct']\n",
        "        status = \"✓ OK\" if diff_pct < 5 else \"⚠ CHECK\"\n",
        "        print(f\"{row['ticker']:<8} {int(row['fiscal_year']):<6} {row['revenue']:>14,.0f} {row['segment_total']:>14,.0f} {diff_pct:>7.1f}% {status:<10}\")\n",
        "\n",
        "        if diff_pct >= 5:\n",
        "            warnings.append(f\"{row['ticker']} FY{int(row['fiscal_year'])}: Segment sum differs by {diff_pct:.1f}%\")\n",
        "\n",
        "# Step 7: Check for NaN values in critical fields\n",
        "print(\"\\n7. DATA QUALITY CHECK (NaN VALUES)\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "critical_fields = {\n",
        "    'consolidated_financials.csv': ['revenue', 'operating_income', 'capex'],\n",
        "    'segment_financials.csv': ['segment_revenue'],\n",
        "    'forward_guidance.csv': ['capex_guidance_midpoint']\n",
        "}\n",
        "\n",
        "for filename, fields in critical_fields.items():\n",
        "    if filename in dataframes:\n",
        "        df = dataframes[filename]\n",
        "        for field in fields:\n",
        "            if field in df.columns:\n",
        "                nan_count = df[field].isna().sum()\n",
        "                if nan_count > 0:\n",
        "                    print(f\"⚠ {filename}.{field}: {nan_count} NaN values\")\n",
        "                    warnings.append(f\"{filename}.{field} has {nan_count} NaN values\")\n",
        "                else:\n",
        "                    print(f\"✓ {filename}.{field}: No NaN values\")\n",
        "\n",
        "# Step 8: Preview consolidated data (FY2024)\n",
        "print(\"\\n8. DATA PREVIEW: CONSOLIDATED FY2024\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "if 'consolidated_financials.csv' in dataframes:\n",
        "    df = dataframes['consolidated_financials.csv']\n",
        "    fy24 = df[df['fiscal_year'] == 2024][['ticker', 'revenue', 'capex', 'operating_income']].sort_values('revenue', ascending=False)\n",
        "    print(fy24.to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VALIDATION SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\nErrors: {len(errors)}\")\n",
        "for e in errors:\n",
        "    print(f\"  ✗ {e}\")\n",
        "\n",
        "print(f\"\\nWarnings: {len(warnings)}\")\n",
        "for w in warnings:\n",
        "    print(f\"  ⚠ {w}\")\n",
        "\n",
        "if len(errors) == 0:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"✓ DATA READY FOR MODEL EXECUTION\")\n",
        "    print(\"  Set USE_SYNTHETIC_DATA = False and run all cells\")\n",
        "    print(\"=\" * 70)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"✗ FIX ERRORS BEFORE PROCEEDING\")\n",
        "    print(\"  Review error messages above and correct data files\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 1: ENVIRONMENT SETUP\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 1: Environment Setup\n",
        "\n",
        "Install dependencies and configure the runtime environment.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 1.1 Install Required Packages\n",
        "# -----------------------------------------------------------------------------\n",
        "!pip install pandas numpy matplotlib seaborn plotly openpyxl kaleido -q\n",
        "!pip install pandas numpy matplotlib seaborn plotly openpyxl python-docx -q\n",
        "!pip install -U kaleido -q\n",
        "\n",
        "# %%\n",
        "# 1.2 Import Libraries\n",
        "# -----------------------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import os\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n",
        "\n",
        "# %%\n",
        "# 1.3 Google Drive Mount (for data persistence)\n",
        "# -----------------------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define project paths\n",
        "PROJECT_PATH = '/content/drive/MyDrive/Projects/CapEx_Scorecard/'\n",
        "DATA_PATH = PROJECT_PATH + 'data/'\n",
        "OUTPUT_PATH = PROJECT_PATH + 'outputs/'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "print(\"✓ Environment setup complete\")\n",
        "print(f\"✓ Project path: {PROJECT_PATH}\")\n",
        "print(f\"✓ Data path: {DATA_PATH}\")\n",
        "print(f\"✓ Output path: {OUTPUT_PATH}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 2: CONFIGURATION & PARAMETERS\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 2: Configuration & Parameters\n",
        "\n",
        "Centralize all adjustable parameters for easy model refresh.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 2.1 Analysis Period\n",
        "# -----------------------------------------------------------------------------\n",
        "FISCAL_YEARS = [2022, 2023, 2024]\n",
        "CURRENT_YEAR = 2024\n",
        "FORWARD_YEAR = 2025\n",
        "\n",
        "# 2.2 Company Universe\n",
        "# -----------------------------------------------------------------------------\n",
        "COMPANIES = {\n",
        "    'AAPL': {'name': 'Apple', 'fy_end': 'September', 'color': '#555555'},\n",
        "    'MSFT': {'name': 'Microsoft', 'fy_end': 'June', 'color': '#00A4EF'},\n",
        "    'GOOGL': {'name': 'Alphabet', 'fy_end': 'December', 'color': '#4285F4'},\n",
        "    'AMZN': {'name': 'Amazon', 'fy_end': 'December', 'color': '#FF9900'},\n",
        "    'META': {'name': 'Meta', 'fy_end': 'December', 'color': '#0668E1'},\n",
        "    'NVDA': {'name': 'NVIDIA', 'fy_end': 'January', 'color': '#76B900'},\n",
        "    'TSLA': {'name': 'Tesla', 'fy_end': 'December', 'color': '#CC0000'}\n",
        "}\n",
        "\n",
        "COMPANY_ORDER = ['NVDA', 'AMZN', 'MSFT', 'AAPL', 'GOOGL', 'META', 'TSLA']\n",
        "\n",
        "# 2.3 Segment Mapping\n",
        "# -----------------------------------------------------------------------------\n",
        "# Defines which segments to analyze for each company\n",
        "SEGMENT_CONFIG = {\n",
        "    'MSFT': {\n",
        "        'segments': ['Intelligent Cloud', 'Productivity and Business Processes',\n",
        "                     'More Personal Computing'],\n",
        "        'ai_primary': 'Intelligent Cloud'\n",
        "    },\n",
        "    'GOOGL': {\n",
        "        'segments': ['Google Services', 'Google Cloud', 'Other Bets'],\n",
        "        'ai_primary': 'Google Cloud'\n",
        "    },\n",
        "    'AMZN': {\n",
        "        'segments': ['AWS', 'North America', 'International'],\n",
        "        'ai_primary': 'AWS'\n",
        "    },\n",
        "    'META': {\n",
        "        'segments': ['Family of Apps', 'Reality Labs'],\n",
        "        'ai_primary': 'Reality Labs'\n",
        "    },\n",
        "    'NVDA': {\n",
        "        'segments': ['Compute & Networking', 'Graphics'],\n",
        "        'ai_primary': 'Compute & Networking'\n",
        "    },\n",
        "    'AAPL': {\n",
        "        'segments': ['Consolidated'],  # No segment-level P&L\n",
        "        'ai_primary': 'Consolidated'\n",
        "    },\n",
        "    'TSLA': {\n",
        "        'segments': ['Automotive', 'Energy Generation and Storage'],\n",
        "        'ai_primary': 'Automotive'\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2.4 Scoring Weights\n",
        "# -----------------------------------------------------------------------------\n",
        "DIMENSION_WEIGHTS = {\n",
        "    'capital_deployment': 0.15,\n",
        "    'conversion_efficiency': 0.35,\n",
        "    'return_quality': 0.30,\n",
        "    'sustainability_risk': 0.20\n",
        "}\n",
        "\n",
        "# Verify weights sum to 1.0\n",
        "assert abs(sum(DIMENSION_WEIGHTS.values()) - 1.0) < 0.001, \"Dimension weights must sum to 1.0\"\n",
        "\n",
        "# 2.5 Classification Thresholds\n",
        "# -----------------------------------------------------------------------------\n",
        "CLASSIFICATION_THRESHOLDS = {\n",
        "    'Capital Efficient': (7.0, 10.0),\n",
        "    'Capital Intensive': (4.0, 6.99),\n",
        "    'Capital Dependent': (1.0, 3.99)\n",
        "}\n",
        "\n",
        "# 2.6 Display Settings\n",
        "# -----------------------------------------------------------------------------\n",
        "CHART_TEMPLATE = 'plotly_white'\n",
        "FIGURE_DPI = 150\n",
        "\n",
        "print(\"✓ Configuration loaded\")\n",
        "print(f\"✓ Analyzing {len(COMPANIES)} companies across {len(FISCAL_YEARS)} fiscal years\")\n",
        "print(f\"✓ Dimension weights: {DIMENSION_WEIGHTS}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 2.5: SYNTHETIC DATA GENERATOR (Development Mode)\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 2.5: Synthetic Data Generator (Development Mode)\n",
        "\n",
        "**PURPOSE**: Generate realistic synthetic data for development and testing.\n",
        "\n",
        "**USAGE**:\n",
        "- Set `USE_SYNTHETIC_DATA = True` to generate and use synthetic data\n",
        "- Set `USE_SYNTHETIC_DATA = False` once real data is available\n",
        "\n",
        "**NOTE**: Replace with real SEC filing data before final analysis.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# Toggle for synthetic vs. real data\n",
        "USE_SYNTHETIC_DATA = False  # Set to False when real data is ready\n",
        "\n",
        "# %%\n",
        "# 2.5.1 Realistic Base Values (FY2024 Approximate Scale)\n",
        "# -----------------------------------------------------------------------------\n",
        "# Based on publicly known ranges to make synthetic data realistic\n",
        "# All values in millions USD\n",
        "\n",
        "BASE_FINANCIALS = {\n",
        "    'AAPL': {\n",
        "        'revenue': 385000, 'gross_margin': 0.46, 'op_margin': 0.30,\n",
        "        'capex_intensity': 0.03, 'rd_intensity': 0.07, 'cash': 65000,\n",
        "        'debt': 110000, 'assets': 350000\n",
        "    },\n",
        "    'MSFT': {\n",
        "        'revenue': 245000, 'gross_margin': 0.70, 'op_margin': 0.44,\n",
        "        'capex_intensity': 0.15, 'rd_intensity': 0.12, 'cash': 80000,\n",
        "        'debt': 50000, 'assets': 470000\n",
        "    },\n",
        "    'GOOGL': {\n",
        "        'revenue': 340000, 'gross_margin': 0.57, 'op_margin': 0.30,\n",
        "        'capex_intensity': 0.12, 'rd_intensity': 0.14, 'cash': 110000,\n",
        "        'debt': 30000, 'assets': 430000\n",
        "    },\n",
        "    'AMZN': {\n",
        "        'revenue': 620000, 'gross_margin': 0.47, 'op_margin': 0.09,\n",
        "        'capex_intensity': 0.10, 'rd_intensity': 0.14, 'cash': 90000,\n",
        "        'debt': 135000, 'assets': 550000\n",
        "    },\n",
        "    'META': {\n",
        "        'revenue': 160000, 'gross_margin': 0.81, 'op_margin': 0.35,\n",
        "        'capex_intensity': 0.20, 'rd_intensity': 0.27, 'cash': 65000,\n",
        "        'debt': 35000, 'assets': 230000\n",
        "    },\n",
        "    'NVDA': {\n",
        "        'revenue': 130000, 'gross_margin': 0.73, 'op_margin': 0.62,\n",
        "        'capex_intensity': 0.04, 'rd_intensity': 0.15, 'cash': 50000,\n",
        "        'debt': 10000, 'assets': 100000\n",
        "    },\n",
        "    'TSLA': {\n",
        "        'revenue': 97000, 'gross_margin': 0.18, 'op_margin': 0.08,\n",
        "        'capex_intensity': 0.10, 'rd_intensity': 0.06, 'cash': 30000,\n",
        "        'debt': 10000, 'assets': 110000\n",
        "    }\n",
        "}\n",
        "\n",
        "# Growth assumptions for synthetic history (annualized)\n",
        "GROWTH_RATES = {\n",
        "    'AAPL': {'revenue': 0.02, 'capex': 0.05},\n",
        "    'MSFT': {'revenue': 0.15, 'capex': 0.35},\n",
        "    'GOOGL': {'revenue': 0.12, 'capex': 0.25},\n",
        "    'AMZN': {'revenue': 0.12, 'capex': 0.20},\n",
        "    'META': {'revenue': 0.20, 'capex': 0.40},\n",
        "    'NVDA': {'revenue': 1.20, 'capex': 0.50},  # Exceptional growth\n",
        "    'TSLA': {'revenue': 0.15, 'capex': 0.10}\n",
        "}\n",
        "\n",
        "# Segment allocation percentages\n",
        "SEGMENT_ALLOCATION = {\n",
        "    'MSFT': {\n",
        "        'Intelligent Cloud': {'revenue_share': 0.43, 'op_margin': 0.45},\n",
        "        'Productivity and Business Processes': {'revenue_share': 0.32, 'op_margin': 0.47},\n",
        "        'More Personal Computing': {'revenue_share': 0.25, 'op_margin': 0.35}\n",
        "    },\n",
        "    'GOOGL': {\n",
        "        'Google Services': {'revenue_share': 0.88, 'op_margin': 0.36},\n",
        "        'Google Cloud': {'revenue_share': 0.11, 'op_margin': 0.05},\n",
        "        'Other Bets': {'revenue_share': 0.01, 'op_margin': -3.00}\n",
        "    },\n",
        "    'AMZN': {\n",
        "        'AWS': {'revenue_share': 0.17, 'op_margin': 0.30},\n",
        "        'North America': {'revenue_share': 0.62, 'op_margin': 0.05},\n",
        "        'International': {'revenue_share': 0.21, 'op_margin': -0.02}\n",
        "    },\n",
        "    'META': {\n",
        "        'Family of Apps': {'revenue_share': 0.98, 'op_margin': 0.50},\n",
        "        'Reality Labs': {'revenue_share': 0.02, 'op_margin': -7.00}\n",
        "    },\n",
        "    'NVDA': {\n",
        "        'Compute & Networking': {'revenue_share': 0.88, 'op_margin': 0.68},\n",
        "        'Graphics': {'revenue_share': 0.12, 'op_margin': 0.45}\n",
        "    },\n",
        "    'TSLA': {\n",
        "        'Automotive': {'revenue_share': 0.85, 'op_margin': 0.10},\n",
        "        'Energy Generation and Storage': {'revenue_share': 0.15, 'op_margin': 0.15}\n",
        "    },\n",
        "    'AAPL': {\n",
        "        'Consolidated': {'revenue_share': 1.00, 'op_margin': 0.30}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Forward guidance estimates for FY2025 (millions USD)\n",
        "FORWARD_GUIDANCE_2025 = {\n",
        "    'AAPL': {'low': 12000, 'high': 14000, 'source': 'Q4 FY2024 Earnings Call'},\n",
        "    'MSFT': {'low': 80000, 'high': 85000, 'source': 'Q2 FY2025 Earnings Call'},\n",
        "    'GOOGL': {'low': 55000, 'high': 60000, 'source': 'Q4 2024 Earnings Call'},\n",
        "    'AMZN': {'low': 100000, 'high': 110000, 'source': 'Q4 2024 Earnings Release'},\n",
        "    'META': {'low': 60000, 'high': 65000, 'source': 'Q4 2024 Earnings Call'},\n",
        "    'NVDA': {'low': 8000, 'high': 12000, 'source': 'Q3 FY2025 Earnings Call'},\n",
        "    'TSLA': {'low': 10000, 'high': 12000, 'source': 'Q4 2024 Earnings Call'}\n",
        "}\n",
        "\n",
        "# %%\n",
        "# 2.5.2 Generate Consolidated Financials\n",
        "# -----------------------------------------------------------------------------\n",
        "def generate_synthetic_consolidated() -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate 3 years of synthetic consolidated financial data.\n",
        "    Works backward from FY2024 base values.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with consolidated financial metrics for all companies and years\n",
        "    \"\"\"\n",
        "    np.random.seed(42)  # Reproducibility\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for ticker, base in BASE_FINANCIALS.items():\n",
        "        growth = GROWTH_RATES[ticker]\n",
        "\n",
        "        for year_offset, year in enumerate([2022, 2023, 2024]):\n",
        "            # Calculate values working backward from 2024\n",
        "            years_from_base = 2024 - year\n",
        "\n",
        "            # Revenue with growth applied backward\n",
        "            revenue = base['revenue'] / ((1 + growth['revenue']) ** years_from_base)\n",
        "\n",
        "            # Add some noise (±3%)\n",
        "            revenue *= (1 + np.random.uniform(-0.03, 0.03))\n",
        "\n",
        "            # Derived metrics\n",
        "            gross_profit = revenue * base['gross_margin'] * (1 + np.random.uniform(-0.02, 0.02))\n",
        "            cost_of_revenue = revenue - gross_profit\n",
        "\n",
        "            rd_expense = revenue * base['rd_intensity'] * (1 + np.random.uniform(-0.01, 0.01))\n",
        "\n",
        "            operating_income = revenue * base['op_margin'] * (1 + np.random.uniform(-0.03, 0.03))\n",
        "\n",
        "            # Net income (rough approximation)\n",
        "            net_income = operating_income * 0.80  # Effective tax ~20%\n",
        "\n",
        "            # CapEx with growth\n",
        "            capex = revenue * base['capex_intensity'] / ((1 + growth['capex']) ** years_from_base)\n",
        "            capex *= (1 + np.random.uniform(-0.05, 0.05))\n",
        "            capex = max(capex, revenue * 0.01)  # Minimum 1% of revenue\n",
        "\n",
        "            # Cash flow (OCF typically 1.2-1.5x net income for tech)\n",
        "            ocf_multiple = np.random.uniform(1.2, 1.5)\n",
        "            operating_cash_flow = net_income * ocf_multiple\n",
        "\n",
        "            # Balance sheet items (less volatile)\n",
        "            assets = base['assets'] / ((1 + 0.10) ** years_from_base)\n",
        "            assets *= (1 + np.random.uniform(-0.05, 0.05))\n",
        "\n",
        "            cash = base['cash'] * (1 + np.random.uniform(-0.10, 0.10))\n",
        "            debt = base['debt'] * (1 + np.random.uniform(-0.05, 0.05))\n",
        "\n",
        "            # D&A (rough: 5-10% of assets)\n",
        "            depreciation = assets * np.random.uniform(0.05, 0.10)\n",
        "\n",
        "            records.append({\n",
        "                'ticker': ticker,\n",
        "                'fiscal_year': year,\n",
        "                'revenue': round(revenue, 0),\n",
        "                'cost_of_revenue': round(cost_of_revenue, 0),\n",
        "                'gross_profit': round(gross_profit, 0),\n",
        "                'rd_expense': round(rd_expense, 0),\n",
        "                'operating_income': round(operating_income, 0),\n",
        "                'net_income': round(net_income, 0),\n",
        "                'total_assets': round(assets, 0),\n",
        "                'total_debt': round(debt, 0),\n",
        "                'cash_and_equivalents': round(cash, 0),\n",
        "                'operating_cash_flow': round(operating_cash_flow, 0),\n",
        "                'capex': round(capex, 0),\n",
        "                'depreciation_amortization': round(depreciation, 0)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "# %%\n",
        "# 2.5.3 Generate Segment Financials\n",
        "# -----------------------------------------------------------------------------\n",
        "def generate_synthetic_segments(df_consolidated: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate segment-level data based on consolidated totals.\n",
        "\n",
        "    Args:\n",
        "        df_consolidated: DataFrame with consolidated financial data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with segment-level revenue and operating income\n",
        "    \"\"\"\n",
        "    np.random.seed(43)\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for _, row in df_consolidated.iterrows():\n",
        "        ticker = row['ticker']\n",
        "        year = row['fiscal_year']\n",
        "        total_revenue = row['revenue']\n",
        "\n",
        "        if ticker in SEGMENT_ALLOCATION:\n",
        "            for segment_name, alloc in SEGMENT_ALLOCATION[ticker].items():\n",
        "                # Segment revenue\n",
        "                seg_revenue = total_revenue * alloc['revenue_share']\n",
        "                seg_revenue *= (1 + np.random.uniform(-0.02, 0.02))\n",
        "\n",
        "                # Segment operating income\n",
        "                seg_op_income = seg_revenue * alloc['op_margin']\n",
        "                seg_op_income *= (1 + np.random.uniform(-0.05, 0.05))\n",
        "\n",
        "                records.append({\n",
        "                    'ticker': ticker,\n",
        "                    'fiscal_year': year,\n",
        "                    'segment_name': segment_name,\n",
        "                    'segment_revenue': round(seg_revenue, 0),\n",
        "                    'segment_operating_income': round(seg_op_income, 0)\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "# %%\n",
        "# 2.5.4 Generate Forward Guidance\n",
        "# -----------------------------------------------------------------------------\n",
        "def generate_synthetic_forward_guidance() -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate forward CapEx guidance data.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with FY2025 CapEx guidance for all companies\n",
        "    \"\"\"\n",
        "    records = []\n",
        "\n",
        "    for ticker, guidance in FORWARD_GUIDANCE_2025.items():\n",
        "        records.append({\n",
        "            'ticker': ticker,\n",
        "            'guidance_year': 2025,\n",
        "            'capex_guidance_low': guidance['low'],\n",
        "            'capex_guidance_high': guidance['high'],\n",
        "            'capex_guidance_midpoint': (guidance['low'] + guidance['high']) / 2,\n",
        "            'source': guidance['source'],\n",
        "            'source_date': '2025-01-15'  # Placeholder\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "# %%\n",
        "# 2.5.5 Generate Purchase Obligations\n",
        "# -----------------------------------------------------------------------------\n",
        "def generate_synthetic_obligations(df_consolidated: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate purchase obligations data.\n",
        "    Typically 1-3x annual CapEx for tech companies with AI buildout.\n",
        "\n",
        "    Args:\n",
        "        df_consolidated: DataFrame with consolidated financial data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with purchase and lease obligations\n",
        "    \"\"\"\n",
        "    np.random.seed(44)\n",
        "\n",
        "    records = []\n",
        "\n",
        "    # Purchase obligations multiplier varies by company strategy\n",
        "    multipliers = {\n",
        "        'AAPL': 1.5, 'MSFT': 2.5, 'GOOGL': 2.0, 'AMZN': 3.0,\n",
        "        'META': 2.5, 'NVDA': 4.0, 'TSLA': 1.5\n",
        "    }\n",
        "\n",
        "    for _, row in df_consolidated.iterrows():\n",
        "        ticker = row['ticker']\n",
        "        year = row['fiscal_year']\n",
        "        capex = row['capex']\n",
        "\n",
        "        mult = multipliers.get(ticker, 2.0)\n",
        "\n",
        "        total_obligations = capex * mult * (1 + np.random.uniform(-0.10, 0.10))\n",
        "        one_year_obligations = total_obligations * 0.40  # ~40% due in 1 year\n",
        "\n",
        "        # Lease obligations (rough approximation)\n",
        "        op_lease = row['total_assets'] * np.random.uniform(0.02, 0.05)\n",
        "        fin_lease = row['total_assets'] * np.random.uniform(0.01, 0.03)\n",
        "\n",
        "        records.append({\n",
        "            'ticker': ticker,\n",
        "            'fiscal_year': year,\n",
        "            'purchase_obligations_total': round(total_obligations, 0),\n",
        "            'purchase_obligations_1yr': round(one_year_obligations, 0),\n",
        "            'operating_lease_obligations': round(op_lease, 0),\n",
        "            'finance_lease_obligations': round(fin_lease, 0)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "# %%\n",
        "# 2.5.6 Generate and Save Synthetic Data\n",
        "# -----------------------------------------------------------------------------\n",
        "if USE_SYNTHETIC_DATA:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"GENERATING SYNTHETIC DATA (Development Mode)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\n⚠️  This is SYNTHETIC data for testing purposes only.\")\n",
        "    print(\"    Replace with real SEC filing data before final analysis.\\n\")\n",
        "\n",
        "    # Generate all datasets\n",
        "    synthetic_consolidated = generate_synthetic_consolidated()\n",
        "    print(f\"✓ Consolidated financials: {len(synthetic_consolidated)} records\")\n",
        "\n",
        "    synthetic_segments = generate_synthetic_segments(synthetic_consolidated)\n",
        "    print(f\"✓ Segment financials: {len(synthetic_segments)} records\")\n",
        "\n",
        "    synthetic_forward = generate_synthetic_forward_guidance()\n",
        "    print(f\"✓ Forward guidance: {len(synthetic_forward)} records\")\n",
        "\n",
        "    synthetic_obligations = generate_synthetic_obligations(synthetic_consolidated)\n",
        "    print(f\"✓ Purchase obligations: {len(synthetic_obligations)} records\")\n",
        "\n",
        "    # Save to CSV\n",
        "    synthetic_consolidated.to_csv(DATA_PATH + 'consolidated_financials.csv', index=False)\n",
        "    synthetic_segments.to_csv(DATA_PATH + 'segment_financials.csv', index=False)\n",
        "    synthetic_forward.to_csv(DATA_PATH + 'forward_guidance.csv', index=False)\n",
        "    synthetic_obligations.to_csv(DATA_PATH + 'purchase_obligations.csv', index=False)\n",
        "\n",
        "    print(f\"\\n✓ Synthetic data saved to: {DATA_PATH}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Preview consolidated data\n",
        "    print(\"\\nSample Consolidated Data (FY2024):\")\n",
        "    display(synthetic_consolidated[synthetic_consolidated['fiscal_year'] == 2024].sort_values('revenue', ascending=False))\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 3: DATA INGESTION\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 3: Data Ingestion\n",
        "\n",
        "Load all financial data from structured CSV files.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 3.1 Data Schema Definitions\n",
        "# -----------------------------------------------------------------------------\n",
        "# Expected columns for each data file\n",
        "\n",
        "CONSOLIDATED_SCHEMA = {\n",
        "    'ticker': str,\n",
        "    'fiscal_year': int,\n",
        "    'revenue': float,\n",
        "    'cost_of_revenue': float,\n",
        "    'gross_profit': float,\n",
        "    'rd_expense': float,\n",
        "    'operating_income': float,\n",
        "    'net_income': float,\n",
        "    'total_assets': float,\n",
        "    'total_debt': float,\n",
        "    'cash_and_equivalents': float,\n",
        "    'operating_cash_flow': float,\n",
        "    'capex': float,\n",
        "    'depreciation_amortization': float\n",
        "}\n",
        "\n",
        "SEGMENT_SCHEMA = {\n",
        "    'ticker': str,\n",
        "    'fiscal_year': int,\n",
        "    'segment_name': str,\n",
        "    'segment_revenue': float,\n",
        "    'segment_operating_income': float\n",
        "}\n",
        "\n",
        "FORWARD_GUIDANCE_SCHEMA = {\n",
        "    'ticker': str,\n",
        "    'guidance_year': int,\n",
        "    'capex_guidance_low': float,\n",
        "    'capex_guidance_high': float,\n",
        "    'capex_guidance_midpoint': float,\n",
        "    'source': str,\n",
        "    'source_date': str\n",
        "}\n",
        "\n",
        "OBLIGATIONS_SCHEMA = {\n",
        "    'ticker': str,\n",
        "    'fiscal_year': int,\n",
        "    'purchase_obligations_total': float,\n",
        "    'purchase_obligations_1yr': float,\n",
        "    'operating_lease_obligations': float,\n",
        "    'finance_lease_obligations': float\n",
        "}\n",
        "\n",
        "# %%\n",
        "# 3.2 Data Loading Functions\n",
        "# -----------------------------------------------------------------------------\n",
        "def load_consolidated_data(filepath: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load consolidated financial data with validation.\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to consolidated_financials.csv\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with consolidated financial data, or None if file not found\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = list(CONSOLIDATED_SCHEMA.keys())\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing columns: {missing_cols}\")\n",
        "\n",
        "        # Sort for consistency\n",
        "        df = df.sort_values(['ticker', 'fiscal_year']).reset_index(drop=True)\n",
        "\n",
        "        print(f\"✓ Loaded consolidated data: {len(df)} records\")\n",
        "        print(f\"  Companies: {df['ticker'].nunique()}\")\n",
        "        print(f\"  Years: {sorted(df['fiscal_year'].unique())}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"✗ File not found: {filepath}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error loading consolidated data: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_segment_data(filepath: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load segment-level financial data with validation.\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to segment_financials.csv\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with segment data, or None if file not found\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = list(SEGMENT_SCHEMA.keys())\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing columns: {missing_cols}\")\n",
        "\n",
        "        df = df.sort_values(['ticker', 'fiscal_year', 'segment_name']).reset_index(drop=True)\n",
        "\n",
        "        print(f\"✓ Loaded segment data: {len(df)} records\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"✗ File not found: {filepath}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error loading segment data: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_forward_guidance(filepath: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load forward CapEx guidance data.\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to forward_guidance.csv\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with forward guidance, or None if file not found\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        df = df.sort_values(['ticker', 'guidance_year']).reset_index(drop=True)\n",
        "\n",
        "        print(f\"✓ Loaded forward guidance: {len(df)} records\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"✗ File not found: {filepath}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error loading forward guidance: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_obligations_data(filepath: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load commitments and obligations data.\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to purchase_obligations.csv\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with obligations data, or None if file not found\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        df = df.sort_values(['ticker', 'fiscal_year']).reset_index(drop=True)\n",
        "\n",
        "        print(f\"✓ Loaded obligations data: {len(df)} records\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"✗ File not found: {filepath}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error loading obligations data: {e}\")\n",
        "        return None\n",
        "\n",
        "# %%\n",
        "# 3.3 Execute Data Loading\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"LOADING DATA FILES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "df_consolidated = load_consolidated_data(DATA_PATH + 'consolidated_financials.csv')\n",
        "df_segment = load_segment_data(DATA_PATH + 'segment_financials.csv')\n",
        "df_forward = load_forward_guidance(DATA_PATH + 'forward_guidance.csv')\n",
        "df_obligations = load_obligations_data(DATA_PATH + 'purchase_obligations.csv')\n",
        "\n",
        "# Store in dictionary for easy access\n",
        "DATA = {\n",
        "    'consolidated': df_consolidated,\n",
        "    'segment': df_segment,\n",
        "    'forward_guidance': df_forward,\n",
        "    'obligations': df_obligations\n",
        "}\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"DATA LOADING SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "for name, df in DATA.items():\n",
        "    status = f\"{len(df)} records\" if df is not None else \"NOT LOADED\"\n",
        "    print(f\"  {name}: {status}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 4: DATA VALIDATION & QUALITY CHECKS\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 4: Data Validation & Quality Checks\n",
        "\n",
        "Ensure data integrity before calculations; flag anomalies.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 4.1 Completeness Check\n",
        "# -----------------------------------------------------------------------------\n",
        "def check_data_completeness(df: pd.DataFrame, expected_companies: list,\n",
        "                            expected_years: list) -> Dict:\n",
        "    \"\"\"\n",
        "    Verify all expected company-year combinations are present.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to check\n",
        "        expected_companies: List of ticker symbols\n",
        "        expected_years: List of fiscal years\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with completeness status and missing combinations\n",
        "    \"\"\"\n",
        "    results = {'complete': True, 'missing': []}\n",
        "\n",
        "    for ticker in expected_companies:\n",
        "        for year in expected_years:\n",
        "            mask = (df['ticker'] == ticker) & (df['fiscal_year'] == year)\n",
        "            if mask.sum() == 0:\n",
        "                results['complete'] = False\n",
        "                results['missing'].append((ticker, year))\n",
        "\n",
        "    return results\n",
        "\n",
        "# %%\n",
        "# 4.2 Reasonableness Checks\n",
        "# -----------------------------------------------------------------------------\n",
        "def check_data_reasonableness(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Flag records that fail basic sanity checks.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with consolidated financial data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with flagged issues\n",
        "    \"\"\"\n",
        "    flags = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        issues = []\n",
        "\n",
        "        # Revenue should be positive\n",
        "        if row['revenue'] <= 0:\n",
        "            issues.append('negative_revenue')\n",
        "\n",
        "        # Gross profit should not exceed revenue\n",
        "        if row['gross_profit'] > row['revenue'] * 1.01:  # Allow 1% tolerance\n",
        "            issues.append('gross_profit_exceeds_revenue')\n",
        "\n",
        "        # Operating income should not exceed gross profit\n",
        "        if row['operating_income'] > row['gross_profit'] * 1.01:\n",
        "            issues.append('operating_income_exceeds_gross_profit')\n",
        "\n",
        "        # CapEx should be positive\n",
        "        if row['capex'] < 0:\n",
        "            issues.append('negative_capex')\n",
        "\n",
        "        # Cash should be positive\n",
        "        if row['cash_and_equivalents'] < 0:\n",
        "            issues.append('negative_cash')\n",
        "\n",
        "        # Assets should exceed debt (for these companies)\n",
        "        if row['total_debt'] > row['total_assets']:\n",
        "            issues.append('debt_exceeds_assets')\n",
        "\n",
        "        if issues:\n",
        "            flags.append({\n",
        "                'ticker': row['ticker'],\n",
        "                'fiscal_year': row['fiscal_year'],\n",
        "                'issues': ', '.join(issues)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(flags)\n",
        "\n",
        "# %%\n",
        "# 4.3 Year-over-Year Change Checks\n",
        "# -----------------------------------------------------------------------------\n",
        "def check_yoy_changes(df: pd.DataFrame, threshold: float = 1.0) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Flag unusual year-over-year changes that may indicate data errors.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with consolidated financial data\n",
        "        threshold: Maximum expected YoY change (1.0 = 100%)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with flagged unusual changes\n",
        "    \"\"\"\n",
        "    flags = []\n",
        "    metrics_to_check = ['revenue', 'capex', 'operating_income', 'total_assets']\n",
        "\n",
        "    for ticker in df['ticker'].unique():\n",
        "        company_df = df[df['ticker'] == ticker].sort_values('fiscal_year')\n",
        "\n",
        "        for metric in metrics_to_check:\n",
        "            values = company_df[metric].values\n",
        "            years = company_df['fiscal_year'].values\n",
        "\n",
        "            for i in range(1, len(values)):\n",
        "                if values[i-1] != 0:\n",
        "                    yoy_change = (values[i] - values[i-1]) / abs(values[i-1])\n",
        "\n",
        "                    # Special handling for NVIDIA's exceptional growth\n",
        "                    adjusted_threshold = threshold * 2 if ticker == 'NVDA' else threshold\n",
        "\n",
        "                    if abs(yoy_change) > adjusted_threshold:\n",
        "                        flags.append({\n",
        "                            'ticker': ticker,\n",
        "                            'fiscal_year': years[i],\n",
        "                            'metric': metric,\n",
        "                            'yoy_change_pct': round(yoy_change * 100, 1),\n",
        "                            'prior_value': round(values[i-1], 0),\n",
        "                            'current_value': round(values[i], 0)\n",
        "                        })\n",
        "\n",
        "    return pd.DataFrame(flags)\n",
        "\n",
        "# %%\n",
        "# 4.4 Execute Validation\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"DATA VALIDATION REPORT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if df_consolidated is not None:\n",
        "    # Completeness check\n",
        "    completeness = check_data_completeness(\n",
        "        df_consolidated,\n",
        "        list(COMPANIES.keys()),\n",
        "        FISCAL_YEARS\n",
        "    )\n",
        "\n",
        "    if completeness['complete']:\n",
        "        print(\"\\n✓ Data completeness: PASS\")\n",
        "        print(f\"  All {len(COMPANIES)} companies × {len(FISCAL_YEARS)} years present\")\n",
        "    else:\n",
        "        print(\"\\n✗ Data completeness: FAIL\")\n",
        "        print(f\"  Missing combinations: {completeness['missing']}\")\n",
        "\n",
        "    # Reasonableness check\n",
        "    reasonableness_flags = check_data_reasonableness(df_consolidated)\n",
        "    if len(reasonableness_flags) == 0:\n",
        "        print(\"\\n✓ Reasonableness checks: PASS\")\n",
        "        print(\"  No data quality issues detected\")\n",
        "    else:\n",
        "        print(f\"\\n✗ Reasonableness checks: {len(reasonableness_flags)} issues found\")\n",
        "        display(reasonableness_flags)\n",
        "\n",
        "    # YoY change check\n",
        "    yoy_flags = check_yoy_changes(df_consolidated, threshold=1.0)\n",
        "    if len(yoy_flags) == 0:\n",
        "        print(\"\\n✓ YoY change checks: PASS\")\n",
        "        print(\"  No unusual year-over-year changes detected\")\n",
        "    else:\n",
        "        print(f\"\\n⚠ YoY change checks: {len(yoy_flags)} unusual changes (review recommended)\")\n",
        "        display(yoy_flags)\n",
        "\n",
        "else:\n",
        "    print(\"\\n✗ Cannot run validation: consolidated data not loaded\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 5: METRIC CALCULATIONS\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 5: Metric Calculations\n",
        "\n",
        "Calculate all metrics required for the four dimensions of the scorecard.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 5.0 Helper Functions\n",
        "# -----------------------------------------------------------------------------\n",
        "def safe_divide(numerator: float, denominator: float, default: float = 0.0) -> float:\n",
        "    \"\"\"\n",
        "    Safe division handling zero denominators and NaN values.\n",
        "\n",
        "    Args:\n",
        "        numerator: Dividend\n",
        "        denominator: Divisor\n",
        "        default: Value to return if division is not possible\n",
        "\n",
        "    Returns:\n",
        "        Result of division or default value\n",
        "    \"\"\"\n",
        "    if denominator == 0 or pd.isna(denominator) or pd.isna(numerator):\n",
        "        return default\n",
        "    return numerator / denominator\n",
        "\n",
        "\n",
        "def calculate_cagr(start_value: float, end_value: float, periods: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Compound Annual Growth Rate.\n",
        "\n",
        "    Args:\n",
        "        start_value: Beginning value\n",
        "        end_value: Ending value\n",
        "        periods: Number of periods\n",
        "\n",
        "    Returns:\n",
        "        CAGR as decimal (0.10 = 10%)\n",
        "    \"\"\"\n",
        "    if start_value <= 0 or end_value <= 0 or periods <= 0:\n",
        "        return np.nan\n",
        "    return (end_value / start_value) ** (1 / periods) - 1\n",
        "\n",
        "# %%\n",
        "# 5.1 Capital Deployment Scale Metrics\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_capital_deployment_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate Dimension 1: Capital Deployment Scale\n",
        "\n",
        "    Metrics:\n",
        "    - CapEx Intensity: CapEx / Revenue\n",
        "    - CapEx Growth Rate: YoY % change in CapEx\n",
        "    - CapEx Coverage: Operating Cash Flow / CapEx\n",
        "    - Total Innovation Investment: (R&D + CapEx) / Revenue\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with consolidated financial data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with capital deployment metrics\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for ticker in df['ticker'].unique():\n",
        "        company_df = df[df['ticker'] == ticker].sort_values('fiscal_year')\n",
        "\n",
        "        for idx, row in company_df.iterrows():\n",
        "            year = row['fiscal_year']\n",
        "\n",
        "            # CapEx Intensity\n",
        "            capex_intensity = safe_divide(row['capex'], row['revenue'])\n",
        "\n",
        "            # CapEx Growth Rate (need prior year)\n",
        "            prior_year_data = company_df[company_df['fiscal_year'] == year - 1]\n",
        "            if len(prior_year_data) > 0:\n",
        "                prior_capex = prior_year_data['capex'].values[0]\n",
        "                capex_growth = safe_divide(row['capex'] - prior_capex, prior_capex)\n",
        "            else:\n",
        "                capex_growth = np.nan\n",
        "\n",
        "            # CapEx Coverage\n",
        "            capex_coverage = safe_divide(row['operating_cash_flow'], row['capex'])\n",
        "\n",
        "            # Total Innovation Investment\n",
        "            innovation_investment = safe_divide(\n",
        "                row['rd_expense'] + row['capex'],\n",
        "                row['revenue']\n",
        "            )\n",
        "\n",
        "            results.append({\n",
        "                'ticker': ticker,\n",
        "                'fiscal_year': year,\n",
        "                'capex_intensity': capex_intensity,\n",
        "                'capex_growth_rate': capex_growth,\n",
        "                'capex_coverage': capex_coverage,\n",
        "                'innovation_investment': innovation_investment\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# %%\n",
        "# 5.2 Conversion Efficiency Metrics\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_conversion_efficiency_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate Dimension 2: Conversion Efficiency\n",
        "\n",
        "    Metrics:\n",
        "    - Revenue Yield on CapEx: Revenue Growth $ / Prior Year CapEx\n",
        "    - Incremental Revenue per CapEx $: ΔRevenue / ΔCapEx (rolling)\n",
        "    - Asset Turnover: Revenue / Total Assets\n",
        "    - Asset Turnover Trend: Change in asset turnover over analysis period\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with consolidated financial data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with conversion efficiency metrics\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for ticker in df['ticker'].unique():\n",
        "        company_df = df[df['ticker'] == ticker].sort_values('fiscal_year')\n",
        "\n",
        "        for idx, row in company_df.iterrows():\n",
        "            year = row['fiscal_year']\n",
        "\n",
        "            # Prior year data\n",
        "            prior_year_data = company_df[company_df['fiscal_year'] == year - 1]\n",
        "\n",
        "            # Revenue Yield on CapEx\n",
        "            if len(prior_year_data) > 0:\n",
        "                prior_revenue = prior_year_data['revenue'].values[0]\n",
        "                prior_capex = prior_year_data['capex'].values[0]\n",
        "                revenue_growth = row['revenue'] - prior_revenue\n",
        "                revenue_yield = safe_divide(revenue_growth, prior_capex)\n",
        "            else:\n",
        "                revenue_yield = np.nan\n",
        "\n",
        "            # Incremental Revenue per CapEx (need 2 prior years for delta)\n",
        "            two_years_prior = company_df[company_df['fiscal_year'] == year - 2]\n",
        "            if len(prior_year_data) > 0 and len(two_years_prior) > 0:\n",
        "                delta_revenue = row['revenue'] - two_years_prior['revenue'].values[0]\n",
        "                delta_capex = row['capex'] + prior_year_data['capex'].values[0]\n",
        "                incremental_efficiency = safe_divide(delta_revenue, delta_capex)\n",
        "            else:\n",
        "                incremental_efficiency = np.nan\n",
        "\n",
        "            # Asset Turnover\n",
        "            asset_turnover = safe_divide(row['revenue'], row['total_assets'])\n",
        "\n",
        "            results.append({\n",
        "                'ticker': ticker,\n",
        "                'fiscal_year': year,\n",
        "                'revenue_yield_on_capex': revenue_yield,\n",
        "                'incremental_revenue_per_capex': incremental_efficiency,\n",
        "                'asset_turnover': asset_turnover\n",
        "            })\n",
        "\n",
        "    # Calculate Asset Turnover Trend (change over analysis period)\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    for ticker in results_df['ticker'].unique():\n",
        "        mask = results_df['ticker'] == ticker\n",
        "        company_data = results_df[mask].sort_values('fiscal_year')\n",
        "\n",
        "        if len(company_data) >= 2:\n",
        "            first_at = company_data['asset_turnover'].iloc[0]\n",
        "            last_at = company_data['asset_turnover'].iloc[-1]\n",
        "            trend = last_at - first_at\n",
        "        else:\n",
        "            trend = np.nan\n",
        "\n",
        "        results_df.loc[mask, 'asset_turnover_trend'] = trend\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# %%\n",
        "# 5.3 Return Quality Metrics\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_return_quality_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate Dimension 3: Return Quality\n",
        "\n",
        "    Metrics:\n",
        "    - Gross Margin: Gross Profit / Revenue\n",
        "    - Gross Margin Change: Current GM - Prior Year GM\n",
        "    - Operating Leverage: Δ Operating Income / Δ Revenue\n",
        "    - FCF Margin: (Operating Cash Flow - CapEx) / Revenue\n",
        "    - FCF Margin Trend: Change over analysis period\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with consolidated financial data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with return quality metrics\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for ticker in df['ticker'].unique():\n",
        "        company_df = df[df['ticker'] == ticker].sort_values('fiscal_year')\n",
        "\n",
        "        for idx, row in company_df.iterrows():\n",
        "            year = row['fiscal_year']\n",
        "\n",
        "            # Gross Margin\n",
        "            gross_margin = safe_divide(row['gross_profit'], row['revenue'])\n",
        "\n",
        "            # Prior year for comparisons\n",
        "            prior_year_data = company_df[company_df['fiscal_year'] == year - 1]\n",
        "\n",
        "            # Gross Margin Change\n",
        "            if len(prior_year_data) > 0:\n",
        "                prior_gm = safe_divide(\n",
        "                    prior_year_data['gross_profit'].values[0],\n",
        "                    prior_year_data['revenue'].values[0]\n",
        "                )\n",
        "                gm_change = gross_margin - prior_gm\n",
        "            else:\n",
        "                gm_change = np.nan\n",
        "\n",
        "            # Operating Leverage\n",
        "            if len(prior_year_data) > 0:\n",
        "                delta_oi = row['operating_income'] - prior_year_data['operating_income'].values[0]\n",
        "                delta_rev = row['revenue'] - prior_year_data['revenue'].values[0]\n",
        "                operating_leverage = safe_divide(delta_oi, delta_rev) if delta_rev != 0 else np.nan\n",
        "            else:\n",
        "                operating_leverage = np.nan\n",
        "\n",
        "            # FCF Margin\n",
        "            fcf = row['operating_cash_flow'] - row['capex']\n",
        "            fcf_margin = safe_divide(fcf, row['revenue'])\n",
        "\n",
        "            results.append({\n",
        "                'ticker': ticker,\n",
        "                'fiscal_year': year,\n",
        "                'gross_margin': gross_margin,\n",
        "                'gross_margin_change': gm_change,\n",
        "                'operating_leverage': operating_leverage,\n",
        "                'fcf_margin': fcf_margin\n",
        "            })\n",
        "\n",
        "    # Calculate FCF Margin Trend\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    for ticker in results_df['ticker'].unique():\n",
        "        mask = results_df['ticker'] == ticker\n",
        "        company_data = results_df[mask].sort_values('fiscal_year')\n",
        "\n",
        "        if len(company_data) >= 2:\n",
        "            first_fcf = company_data['fcf_margin'].iloc[0]\n",
        "            last_fcf = company_data['fcf_margin'].iloc[-1]\n",
        "            trend = last_fcf - first_fcf\n",
        "        else:\n",
        "            trend = np.nan\n",
        "\n",
        "        results_df.loc[mask, 'fcf_margin_trend'] = trend\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# %%\n",
        "# 5.4 Sustainability & Risk Metrics\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_sustainability_metrics(df: pd.DataFrame,\n",
        "                                     df_obligations: pd.DataFrame = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate Dimension 4: Sustainability & Risk\n",
        "\n",
        "    Metrics:\n",
        "    - FCF After CapEx: Operating Cash Flow - CapEx\n",
        "    - FCF After CapEx Margin: (OCF - CapEx) / Revenue\n",
        "    - Net Debt to EBITDA: (Total Debt - Cash) / (Operating Income + D&A)\n",
        "    - CapEx Commitment Risk: Purchase Obligations / Cash\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with consolidated financial data\n",
        "        df_obligations: DataFrame with purchase obligations data (optional)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with sustainability metrics\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for ticker in df['ticker'].unique():\n",
        "        company_df = df[df['ticker'] == ticker].sort_values('fiscal_year')\n",
        "\n",
        "        for idx, row in company_df.iterrows():\n",
        "            year = row['fiscal_year']\n",
        "\n",
        "            # FCF After CapEx\n",
        "            fcf_after_capex = row['operating_cash_flow'] - row['capex']\n",
        "            fcf_after_capex_margin = safe_divide(fcf_after_capex, row['revenue'])\n",
        "\n",
        "            # EBITDA proxy (Operating Income + D&A)\n",
        "            ebitda = row['operating_income'] + row['depreciation_amortization']\n",
        "\n",
        "            # Net Debt\n",
        "            net_debt = row['total_debt'] - row['cash_and_equivalents']\n",
        "\n",
        "            # Net Debt to EBITDA\n",
        "            net_debt_to_ebitda = safe_divide(net_debt, ebitda) if ebitda > 0 else np.nan\n",
        "\n",
        "            # CapEx Commitment Risk (from obligations data)\n",
        "            commitment_risk = np.nan\n",
        "            if df_obligations is not None:\n",
        "                oblig_data = df_obligations[\n",
        "                    (df_obligations['ticker'] == ticker) &\n",
        "                    (df_obligations['fiscal_year'] == year)\n",
        "                ]\n",
        "                if len(oblig_data) > 0:\n",
        "                    purchase_oblig = oblig_data['purchase_obligations_total'].values[0]\n",
        "                    commitment_risk = safe_divide(purchase_oblig, row['cash_and_equivalents'])\n",
        "\n",
        "            results.append({\n",
        "                'ticker': ticker,\n",
        "                'fiscal_year': year,\n",
        "                'fcf_after_capex': fcf_after_capex,\n",
        "                'fcf_after_capex_margin': fcf_after_capex_margin,\n",
        "                'net_debt_to_ebitda': net_debt_to_ebitda,\n",
        "                'capex_commitment_risk': commitment_risk\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# %%\n",
        "# 5.5 Execute All Metric Calculations\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"CALCULATING METRICS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if df_consolidated is not None:\n",
        "    # Calculate each dimension's metrics\n",
        "    metrics_deployment = calculate_capital_deployment_metrics(df_consolidated)\n",
        "    print(f\"\\n✓ Capital Deployment metrics: {len(metrics_deployment)} records\")\n",
        "\n",
        "    metrics_conversion = calculate_conversion_efficiency_metrics(df_consolidated)\n",
        "    print(f\"✓ Conversion Efficiency metrics: {len(metrics_conversion)} records\")\n",
        "\n",
        "    metrics_return = calculate_return_quality_metrics(df_consolidated)\n",
        "    print(f\"✓ Return Quality metrics: {len(metrics_return)} records\")\n",
        "\n",
        "    metrics_sustainability = calculate_sustainability_metrics(\n",
        "        df_consolidated,\n",
        "        df_obligations\n",
        "    )\n",
        "    print(f\"✓ Sustainability metrics: {len(metrics_sustainability)} records\")\n",
        "\n",
        "    # Merge all metrics into single DataFrame\n",
        "    df_metrics = metrics_deployment.merge(\n",
        "        metrics_conversion, on=['ticker', 'fiscal_year']\n",
        "    ).merge(\n",
        "        metrics_return, on=['ticker', 'fiscal_year']\n",
        "    ).merge(\n",
        "        metrics_sustainability, on=['ticker', 'fiscal_year']\n",
        "    )\n",
        "\n",
        "    print(f\"\\n✓ Combined metrics DataFrame: {df_metrics.shape[0]} rows × {df_metrics.shape[1]} columns\")\n",
        "\n",
        "    # Display metrics for current year\n",
        "    print(f\"\\nMetrics Summary (FY{CURRENT_YEAR}):\")\n",
        "    display(df_metrics[df_metrics['fiscal_year'] == CURRENT_YEAR].round(3))\n",
        "\n",
        "else:\n",
        "    print(\"\\n✗ Cannot calculate metrics: consolidated data not loaded\")\n",
        "    df_metrics = None\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 6: SCORING ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 6: Scoring Engine\n",
        "\n",
        "Convert raw metrics to 1-10 scores using percentile ranking within the peer group.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 6.1 Percentile Scoring Function\n",
        "# -----------------------------------------------------------------------------\n",
        "def percentile_score(values: pd.Series, higher_is_better: bool = True) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Convert values to 1-10 score based on percentile rank within peer group.\n",
        "\n",
        "    Args:\n",
        "        values: Series of metric values\n",
        "        higher_is_better: If True, higher values get higher scores\n",
        "\n",
        "    Returns:\n",
        "        Series of scores from 1-10\n",
        "    \"\"\"\n",
        "    # Handle NaN values\n",
        "    valid_mask = ~values.isna()\n",
        "    scores = pd.Series(index=values.index, dtype=float)\n",
        "\n",
        "    if valid_mask.sum() == 0:\n",
        "        return scores\n",
        "\n",
        "    # Calculate percentile ranks (0-1)\n",
        "    ranks = values[valid_mask].rank(pct=True)\n",
        "\n",
        "    # Flip if lower is better\n",
        "    if not higher_is_better:\n",
        "        ranks = 1 - ranks\n",
        "\n",
        "    # Scale to 1-10\n",
        "    scores[valid_mask] = 1 + (ranks * 9)\n",
        "\n",
        "    return scores\n",
        "\n",
        "# %%\n",
        "# 6.2 Metric Scoring Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "# Define direction for each metric (True = higher is better)\n",
        "METRIC_DIRECTION = {\n",
        "    # Capital Deployment\n",
        "    'capex_intensity': True,  # Higher intensity = more commitment to AI\n",
        "    'capex_growth_rate': True,  # Higher growth = accelerating investment\n",
        "    'capex_coverage': True,  # Higher coverage = better self-funding\n",
        "    'innovation_investment': True,  # Higher = more total investment\n",
        "\n",
        "    # Conversion Efficiency\n",
        "    'revenue_yield_on_capex': True,  # Higher yield = better conversion\n",
        "    'incremental_revenue_per_capex': True,  # Higher = better marginal return\n",
        "    'asset_turnover': True,  # Higher = more efficient asset use\n",
        "    'asset_turnover_trend': True,  # Improving trend is better\n",
        "\n",
        "    # Return Quality\n",
        "    'gross_margin': True,  # Higher margin = better\n",
        "    'gross_margin_change': True,  # Improving margin = better\n",
        "    'operating_leverage': True,  # Higher leverage = better\n",
        "    'fcf_margin': True,  # Higher FCF margin = better\n",
        "    'fcf_margin_trend': True,  # Improving trend = better\n",
        "\n",
        "    # Sustainability\n",
        "    'fcf_after_capex': True,  # Higher = better\n",
        "    'fcf_after_capex_margin': True,  # Higher = better\n",
        "    'net_debt_to_ebitda': False,  # Lower leverage = better\n",
        "    'capex_commitment_risk': False  # Lower commitment risk = better\n",
        "}\n",
        "\n",
        "# Metric to Dimension mapping\n",
        "METRIC_TO_DIMENSION = {\n",
        "    'capex_intensity': 'capital_deployment',\n",
        "    'capex_growth_rate': 'capital_deployment',\n",
        "    'capex_coverage': 'capital_deployment',\n",
        "    'innovation_investment': 'capital_deployment',\n",
        "\n",
        "    'revenue_yield_on_capex': 'conversion_efficiency',\n",
        "    'incremental_revenue_per_capex': 'conversion_efficiency',\n",
        "    'asset_turnover': 'conversion_efficiency',\n",
        "    'asset_turnover_trend': 'conversion_efficiency',\n",
        "\n",
        "    'gross_margin': 'return_quality',\n",
        "    'gross_margin_change': 'return_quality',\n",
        "    'operating_leverage': 'return_quality',\n",
        "    'fcf_margin': 'return_quality',\n",
        "    'fcf_margin_trend': 'return_quality',\n",
        "\n",
        "    'fcf_after_capex': 'sustainability_risk',\n",
        "    'fcf_after_capex_margin': 'sustainability_risk',\n",
        "    'net_debt_to_ebitda': 'sustainability_risk',\n",
        "    'capex_commitment_risk': 'sustainability_risk'\n",
        "}\n",
        "\n",
        "# %%\n",
        "# 6.3 Score All Metrics\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_metric_scores(df_metrics: pd.DataFrame,\n",
        "                           year: int = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate scores for all metrics.\n",
        "\n",
        "    Args:\n",
        "        df_metrics: DataFrame with raw metric values\n",
        "        year: If specified, score only for that year (cross-sectional)\n",
        "              If None, score across all years (panel)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with '_score' columns added for each metric\n",
        "    \"\"\"\n",
        "    if year is not None:\n",
        "        df_to_score = df_metrics[df_metrics['fiscal_year'] == year].copy()\n",
        "    else:\n",
        "        df_to_score = df_metrics.copy()\n",
        "\n",
        "    for metric, direction in METRIC_DIRECTION.items():\n",
        "        if metric in df_to_score.columns:\n",
        "            score_col = f\"{metric}_score\"\n",
        "            df_to_score[score_col] = percentile_score(\n",
        "                df_to_score[metric],\n",
        "                higher_is_better=direction\n",
        "            )\n",
        "\n",
        "    return df_to_score\n",
        "\n",
        "# %%\n",
        "# 6.4 Calculate Dimension Scores\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_dimension_scores(df_scored: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Aggregate metric scores into dimension scores.\n",
        "\n",
        "    Args:\n",
        "        df_scored: DataFrame with individual metric scores\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with dimension score columns added\n",
        "    \"\"\"\n",
        "    df = df_scored.copy()\n",
        "\n",
        "    for dimension in DIMENSION_WEIGHTS.keys():\n",
        "        # Find all metrics for this dimension\n",
        "        dimension_metrics = [\n",
        "            m for m, d in METRIC_TO_DIMENSION.items()\n",
        "            if d == dimension\n",
        "        ]\n",
        "\n",
        "        # Find corresponding score columns\n",
        "        score_cols = [f\"{m}_score\" for m in dimension_metrics if f\"{m}_score\" in df.columns]\n",
        "\n",
        "        if score_cols:\n",
        "            # Calculate mean of available scores (handles NaN)\n",
        "            df[f\"{dimension}_score\"] = df[score_cols].mean(axis=1, skipna=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# %%\n",
        "# 6.5 Calculate Overall Score\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_overall_score(df_dimension_scores: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate weighted overall efficiency score.\n",
        "\n",
        "    Args:\n",
        "        df_dimension_scores: DataFrame with dimension scores\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with overall_score and classification columns\n",
        "    \"\"\"\n",
        "    df = df_dimension_scores.copy()\n",
        "\n",
        "    overall_score = pd.Series(0.0, index=df.index)\n",
        "\n",
        "    for dimension, weight in DIMENSION_WEIGHTS.items():\n",
        "        score_col = f\"{dimension}_score\"\n",
        "        if score_col in df.columns:\n",
        "            # Handle NaN by using 5.0 (neutral) as fallback\n",
        "            dim_scores = df[score_col].fillna(5.0)\n",
        "            overall_score += dim_scores * weight\n",
        "\n",
        "    df['overall_score'] = overall_score\n",
        "\n",
        "    # Add classification\n",
        "    df['classification'] = df['overall_score'].apply(classify_score)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def classify_score(score: float) -> str:\n",
        "    \"\"\"\n",
        "    Map score to classification tier.\n",
        "\n",
        "    Args:\n",
        "        score: Overall score (1-10)\n",
        "\n",
        "    Returns:\n",
        "        Classification string\n",
        "    \"\"\"\n",
        "    if pd.isna(score):\n",
        "        return 'Unclassified'\n",
        "\n",
        "    for classification, (low, high) in CLASSIFICATION_THRESHOLDS.items():\n",
        "        if low <= score <= high:\n",
        "            return classification\n",
        "\n",
        "    return 'Unclassified'\n",
        "\n",
        "# %%\n",
        "# 6.6 Execute Scoring\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"CALCULATING SCORES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if df_metrics is not None:\n",
        "    # Score for current year only (cross-sectional comparison)\n",
        "    df_scored = calculate_metric_scores(df_metrics, year=CURRENT_YEAR)\n",
        "    print(f\"\\n✓ Metric scores calculated for FY{CURRENT_YEAR}\")\n",
        "\n",
        "    # Calculate dimension scores\n",
        "    df_scored = calculate_dimension_scores(df_scored)\n",
        "    print(\"✓ Dimension scores calculated\")\n",
        "\n",
        "    # Calculate overall score\n",
        "    df_final_scores = calculate_overall_score(df_scored)\n",
        "    print(\"✓ Overall scores and classifications assigned\")\n",
        "\n",
        "    # Display summary\n",
        "    summary_cols = [\n",
        "        'ticker', 'fiscal_year',\n",
        "        'capital_deployment_score', 'conversion_efficiency_score',\n",
        "        'return_quality_score', 'sustainability_risk_score',\n",
        "        'overall_score', 'classification'\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"SCORECARD RESULTS (FY{CURRENT_YEAR})\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "\n",
        "    display(\n",
        "        df_final_scores[summary_cols]\n",
        "        .sort_values('overall_score', ascending=False)\n",
        "        .round(2)\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\"\\n✗ Cannot calculate scores: metrics not available\")\n",
        "    df_final_scores = None\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 7: SEGMENT-LEVEL ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 7: Segment-Level Analysis\n",
        "\n",
        "Deep-dive into AI-primary segments for companies with segment reporting.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 7.1 Segment Metric Calculations\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_segment_metrics(df_segment: pd.DataFrame,\n",
        "                              df_consolidated: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate segment-level efficiency metrics.\n",
        "\n",
        "    Args:\n",
        "        df_segment: DataFrame with segment-level data\n",
        "        df_consolidated: DataFrame with consolidated data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with segment metrics\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for _, row in df_segment.iterrows():\n",
        "        ticker = row['ticker']\n",
        "        year = row['fiscal_year']\n",
        "\n",
        "        # Get consolidated data for this company-year\n",
        "        consol_data = df_consolidated[\n",
        "            (df_consolidated['ticker'] == ticker) &\n",
        "            (df_consolidated['fiscal_year'] == year)\n",
        "        ]\n",
        "\n",
        "        if len(consol_data) == 0:\n",
        "            continue\n",
        "\n",
        "        total_revenue = consol_data['revenue'].values[0]\n",
        "\n",
        "        # Segment Revenue Contribution\n",
        "        revenue_contribution = safe_divide(row['segment_revenue'], total_revenue)\n",
        "\n",
        "        # Segment Operating Margin\n",
        "        segment_op_margin = safe_divide(\n",
        "            row['segment_operating_income'],\n",
        "            row['segment_revenue']\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            'ticker': ticker,\n",
        "            'fiscal_year': year,\n",
        "            'segment_name': row['segment_name'],\n",
        "            'segment_revenue': row['segment_revenue'],\n",
        "            'segment_operating_income': row['segment_operating_income'],\n",
        "            'revenue_contribution': revenue_contribution,\n",
        "            'segment_operating_margin': segment_op_margin\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# %%\n",
        "# 7.2 AI-Primary Segment Comparison\n",
        "# -----------------------------------------------------------------------------\n",
        "def analyze_ai_primary_segments(df_segment_metrics: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extract and compare AI-primary segments across companies.\n",
        "\n",
        "    Args:\n",
        "        df_segment_metrics: DataFrame with segment metrics\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with AI-primary segment data only\n",
        "    \"\"\"\n",
        "    ai_segments = []\n",
        "\n",
        "    for ticker, config in SEGMENT_CONFIG.items():\n",
        "        ai_segment_name = config['ai_primary']\n",
        "\n",
        "        segment_data = df_segment_metrics[\n",
        "            (df_segment_metrics['ticker'] == ticker) &\n",
        "            (df_segment_metrics['segment_name'] == ai_segment_name)\n",
        "        ]\n",
        "\n",
        "        if len(segment_data) > 0:\n",
        "            ai_segments.append(segment_data)\n",
        "\n",
        "    if ai_segments:\n",
        "        return pd.concat(ai_segments, ignore_index=True)\n",
        "    return pd.DataFrame()\n",
        "\n",
        "# %%\n",
        "# 7.3 Segment Growth Analysis\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_segment_growth(df_segment_metrics: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate YoY growth for segments.\n",
        "\n",
        "    Args:\n",
        "        df_segment_metrics: DataFrame with segment metrics\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with segment growth metrics\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for ticker in df_segment_metrics['ticker'].unique():\n",
        "        ticker_data = df_segment_metrics[df_segment_metrics['ticker'] == ticker]\n",
        "\n",
        "        for segment in ticker_data['segment_name'].unique():\n",
        "            segment_data = ticker_data[\n",
        "                ticker_data['segment_name'] == segment\n",
        "            ].sort_values('fiscal_year')\n",
        "\n",
        "            for i in range(1, len(segment_data)):\n",
        "                current = segment_data.iloc[i]\n",
        "                prior = segment_data.iloc[i-1]\n",
        "\n",
        "                # Revenue growth\n",
        "                revenue_growth = safe_divide(\n",
        "                    current['segment_revenue'] - prior['segment_revenue'],\n",
        "                    prior['segment_revenue']\n",
        "                )\n",
        "\n",
        "                # Operating income growth (handle negative to positive transitions)\n",
        "                if prior['segment_operating_income'] != 0:\n",
        "                    oi_growth = safe_divide(\n",
        "                        current['segment_operating_income'] - prior['segment_operating_income'],\n",
        "                        abs(prior['segment_operating_income'])\n",
        "                    )\n",
        "                else:\n",
        "                    oi_growth = np.nan\n",
        "\n",
        "                # Margin change\n",
        "                margin_change = current['segment_operating_margin'] - prior['segment_operating_margin']\n",
        "\n",
        "                results.append({\n",
        "                    'ticker': ticker,\n",
        "                    'fiscal_year': current['fiscal_year'],\n",
        "                    'segment_name': segment,\n",
        "                    'revenue_growth': revenue_growth,\n",
        "                    'operating_income_growth': oi_growth,\n",
        "                    'margin_change': margin_change\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# %%\n",
        "# 7.4 Execute Segment Analysis\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"SEGMENT-LEVEL ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if df_segment is not None and df_consolidated is not None:\n",
        "    # Calculate segment metrics\n",
        "    df_segment_metrics = calculate_segment_metrics(df_segment, df_consolidated)\n",
        "    print(f\"\\n✓ Segment metrics calculated: {len(df_segment_metrics)} records\")\n",
        "\n",
        "    # Extract AI-primary segments\n",
        "    df_ai_segments = analyze_ai_primary_segments(df_segment_metrics)\n",
        "    print(f\"✓ AI-primary segments identified: {len(df_ai_segments)} records\")\n",
        "\n",
        "    # Calculate segment growth\n",
        "    df_segment_growth = calculate_segment_growth(df_segment_metrics)\n",
        "    print(f\"✓ Segment growth calculated: {len(df_segment_growth)} records\")\n",
        "\n",
        "    # Display AI segment comparison for current year\n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"AI-PRIMARY SEGMENT COMPARISON (FY{CURRENT_YEAR})\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "\n",
        "    ai_current = df_ai_segments[df_ai_segments['fiscal_year'] == CURRENT_YEAR].copy()\n",
        "    ai_current['company'] = ai_current['ticker'].map(lambda x: COMPANIES[x]['name'])\n",
        "\n",
        "    display(\n",
        "        ai_current[['company', 'segment_name', 'segment_revenue',\n",
        "                   'segment_operating_income', 'revenue_contribution',\n",
        "                   'segment_operating_margin']]\n",
        "        .sort_values('segment_operating_margin', ascending=False)\n",
        "        .round(3)\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\"\\n✗ Cannot perform segment analysis: data not available\")\n",
        "    df_segment_metrics = None\n",
        "    df_ai_segments = None\n",
        "    df_segment_growth = None\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 8: FORWARD GUIDANCE INTEGRATION\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 8: Forward Guidance Integration\n",
        "\n",
        "Incorporate FY2025 CapEx guidance as a forward indicator.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 8.1 Forward CapEx Analysis\n",
        "# -----------------------------------------------------------------------------\n",
        "def analyze_forward_guidance(df_forward: pd.DataFrame,\n",
        "                             df_consolidated: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Analyze forward CapEx guidance relative to historical patterns.\n",
        "\n",
        "    Args:\n",
        "        df_forward: DataFrame with forward guidance\n",
        "        df_consolidated: DataFrame with historical data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with forward guidance analysis\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for ticker in df_forward['ticker'].unique():\n",
        "        # Get latest guidance\n",
        "        guidance_data = df_forward[df_forward['ticker'] == ticker]\n",
        "        if len(guidance_data) == 0:\n",
        "            continue\n",
        "        guidance = guidance_data.iloc[-1]\n",
        "\n",
        "        # Get historical data\n",
        "        historical = df_consolidated[df_consolidated['ticker'] == ticker]\n",
        "        if len(historical) == 0:\n",
        "            continue\n",
        "\n",
        "        # Get latest actual year\n",
        "        latest_year = historical['fiscal_year'].max()\n",
        "        latest_actual = historical[historical['fiscal_year'] == latest_year].iloc[0]\n",
        "\n",
        "        # Calculate guidance vs. actual\n",
        "        guidance_vs_actual = safe_divide(\n",
        "            guidance['capex_guidance_midpoint'],\n",
        "            latest_actual['capex']\n",
        "        ) - 1\n",
        "\n",
        "        # Calculate guidance as % of latest revenue\n",
        "        guidance_intensity = safe_divide(\n",
        "            guidance['capex_guidance_midpoint'],\n",
        "            latest_actual['revenue']\n",
        "        )\n",
        "\n",
        "        # Historical average CapEx intensity\n",
        "        historical_intensity = (historical['capex'] / historical['revenue']).mean()\n",
        "\n",
        "        # Intensity change\n",
        "        intensity_change = guidance_intensity - historical_intensity\n",
        "\n",
        "        results.append({\n",
        "            'ticker': ticker,\n",
        "            'company': COMPANIES[ticker]['name'],\n",
        "            'guidance_year': int(guidance['guidance_year']),\n",
        "            'capex_guidance_midpoint': guidance['capex_guidance_midpoint'],\n",
        "            'latest_actual_capex': latest_actual['capex'],\n",
        "            'guidance_vs_actual_pct': guidance_vs_actual,\n",
        "            'guidance_capex_intensity': guidance_intensity,\n",
        "            'historical_avg_intensity': historical_intensity,\n",
        "            'intensity_change': intensity_change,\n",
        "            'source': guidance['source'],\n",
        "            'source_date': guidance['source_date']\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# %%\n",
        "# 8.2 Forward Indicator Scoring\n",
        "# -----------------------------------------------------------------------------\n",
        "def score_forward_guidance(df_forward_analysis: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Classify companies based on forward guidance trajectory.\n",
        "\n",
        "    Args:\n",
        "        df_forward_analysis: DataFrame with forward guidance analysis\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with investment trajectory classification\n",
        "    \"\"\"\n",
        "    df = df_forward_analysis.copy()\n",
        "\n",
        "    def classify_trajectory(intensity_change):\n",
        "        \"\"\"Classify investment trajectory based on intensity change.\"\"\"\n",
        "        if pd.isna(intensity_change):\n",
        "            return 'Unknown'\n",
        "        if intensity_change > 0.02:  # >2% increase in intensity\n",
        "            return 'Accelerating'\n",
        "        elif intensity_change < -0.02:  # >2% decrease\n",
        "            return 'Decelerating'\n",
        "        else:\n",
        "            return 'Stable'\n",
        "\n",
        "    df['investment_trajectory'] = df['intensity_change'].apply(classify_trajectory)\n",
        "\n",
        "    return df\n",
        "\n",
        "# %%\n",
        "# 8.3 Execute Forward Guidance Analysis\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"FORWARD GUIDANCE ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if df_forward is not None and df_consolidated is not None:\n",
        "    # Analyze forward guidance\n",
        "    df_forward_analysis = analyze_forward_guidance(df_forward, df_consolidated)\n",
        "    print(f\"\\n✓ Forward guidance analyzed: {len(df_forward_analysis)} companies\")\n",
        "\n",
        "    # Score and classify trajectories\n",
        "    df_forward_scored = score_forward_guidance(df_forward_analysis)\n",
        "    print(\"✓ Investment trajectories classified\")\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"FY{FORWARD_YEAR} CAPEX GUIDANCE ANALYSIS\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "\n",
        "    display_cols = [\n",
        "        'company', 'guidance_year', 'capex_guidance_midpoint',\n",
        "        'latest_actual_capex', 'guidance_vs_actual_pct',\n",
        "        'intensity_change', 'investment_trajectory'\n",
        "    ]\n",
        "\n",
        "    display(\n",
        "        df_forward_scored[display_cols]\n",
        "        .sort_values('guidance_vs_actual_pct', ascending=False)\n",
        "        .round(3)\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\"\\n✗ Cannot analyze forward guidance: data not available\")\n",
        "    df_forward_analysis = None\n",
        "    df_forward_scored = None\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 9: VISUALIZATIONS\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 9: Visualizations\n",
        "\n",
        "Create executive-ready charts for the scorecard.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 9.1 Scorecard Heatmap\n",
        "# -----------------------------------------------------------------------------\n",
        "def create_scorecard_heatmap(df_scores: pd.DataFrame, year: int) -> go.Figure:\n",
        "    \"\"\"\n",
        "    Create heatmap showing dimension scores by company.\n",
        "\n",
        "    Args:\n",
        "        df_scores: DataFrame with final scores\n",
        "        year: Fiscal year to display\n",
        "\n",
        "    Returns:\n",
        "        Plotly Figure object\n",
        "    \"\"\"\n",
        "    df_year = df_scores[df_scores['fiscal_year'] == year].copy()\n",
        "    df_year = df_year.sort_values('overall_score', ascending=True)\n",
        "\n",
        "    # Prepare data for heatmap\n",
        "    companies = [COMPANIES[t]['name'] for t in df_year['ticker']]\n",
        "    dimensions = ['Capital\\nDeployment', 'Conversion\\nEfficiency',\n",
        "                  'Return\\nQuality', 'Sustainability\\n& Risk', 'Overall']\n",
        "\n",
        "    score_cols = ['capital_deployment_score', 'conversion_efficiency_score',\n",
        "                  'return_quality_score', 'sustainability_risk_score', 'overall_score']\n",
        "\n",
        "    z_data = df_year[score_cols].values\n",
        "\n",
        "    # Create heatmap\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "        z=z_data,\n",
        "        x=dimensions,\n",
        "        y=companies,\n",
        "        colorscale='RdYlGn',\n",
        "        zmin=1,\n",
        "        zmax=10,\n",
        "        text=np.round(z_data, 1),\n",
        "        texttemplate='%{text}',\n",
        "        textfont={'size': 12, 'color': 'black'},\n",
        "        hovertemplate='%{y}<br>%{x}: %{z:.1f}<extra></extra>',\n",
        "        colorbar=dict(title='Score', tickvals=[1, 4, 7, 10])\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=dict(\n",
        "            text=f'Capital Allocation Efficiency Scorecard (FY{year})',\n",
        "            font=dict(size=18)\n",
        "        ),\n",
        "        xaxis_title='',\n",
        "        yaxis_title='',\n",
        "        template=CHART_TEMPLATE,\n",
        "        height=450,\n",
        "        width=800,\n",
        "        margin=dict(l=120, r=50, t=80, b=50)\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# %%\n",
        "# 9.2 Dimension Comparison Radar Chart (CORRECTED)\n",
        "# -----------------------------------------------------------------------------\n",
        "def create_radar_chart(df_scores: pd.DataFrame, year: int,\n",
        "                       companies_to_show: list = None) -> go.Figure:\n",
        "    \"\"\"\n",
        "    Create radar chart comparing companies across dimensions.\n",
        "    Uses small multiples layout for clarity.\n",
        "    \"\"\"\n",
        "    from plotly.subplots import make_subplots\n",
        "\n",
        "    df_year = df_scores[df_scores['fiscal_year'] == year].copy()\n",
        "    df_year = df_year.sort_values('overall_score', ascending=False)\n",
        "\n",
        "    if companies_to_show:\n",
        "        df_year = df_year[df_year['ticker'].isin(companies_to_show)]\n",
        "\n",
        "    categories = ['Conversion<br>Efficiency', 'Capital<br>Deployment',\n",
        "                  'Sustainability<br>& Risk', 'Return<br>Quality']\n",
        "\n",
        "    # Create 2x4 subplot grid\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=4,\n",
        "        specs=[[{'type': 'polar'}] * 4, [{'type': 'polar'}] * 4],\n",
        "        subplot_titles=[COMPANIES[t]['name'] for t in df_year['ticker'].tolist()] + [''],\n",
        "        horizontal_spacing=0.08,\n",
        "        vertical_spacing=0.12\n",
        "    )\n",
        "\n",
        "    positions = [(1,1), (1,2), (1,3), (1,4), (2,1), (2,2), (2,3)]\n",
        "\n",
        "    for idx, (_, row) in enumerate(df_year.iterrows()):\n",
        "        if idx >= 7:\n",
        "            break\n",
        "\n",
        "        ticker = row['ticker']\n",
        "        color = COMPANIES[ticker]['color']\n",
        "        r, c = positions[idx]\n",
        "\n",
        "        values = [\n",
        "            row['conversion_efficiency_score'],\n",
        "            row['capital_deployment_score'],\n",
        "            row['sustainability_risk_score'],\n",
        "            row['return_quality_score']\n",
        "        ]\n",
        "        values.append(values[0])\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Scatterpolar(\n",
        "                r=values,\n",
        "                theta=categories + [categories[0]],\n",
        "                name=COMPANIES[ticker]['name'],\n",
        "                line=dict(color=color, width=2),\n",
        "                fill='toself',\n",
        "                fillcolor=color,\n",
        "                opacity=0.4,\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=r, col=c\n",
        "        )\n",
        "\n",
        "    # Update all polar axes\n",
        "    for i in range(1, 8):\n",
        "        fig.update_polars(\n",
        "            radialaxis=dict(\n",
        "                visible=True,\n",
        "                range=[0, 10],\n",
        "                tickvals=[2, 4, 6, 8, 10],\n",
        "                tickfont=dict(size=8)\n",
        "            ),\n",
        "            angularaxis=dict(\n",
        "                tickfont=dict(size=9)\n",
        "            ),\n",
        "            selector=dict(subplot=f'polar{i}' if i > 1 else 'polar')\n",
        "        )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=dict(\n",
        "            text=f'Dimension Comparison by Company (FY{year})<br><sup>Ranked by Overall Score: Highest (top-left) to Lowest (bottom-right)</sup>',\n",
        "            font=dict(size=16),\n",
        "            x=0.5\n",
        "        ),\n",
        "        template=CHART_TEMPLATE,\n",
        "        height=700,\n",
        "        width=1000,\n",
        "        showlegend=False\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# %%\n",
        "# 9.3 CapEx Intensity Trend Chart\n",
        "# -----------------------------------------------------------------------------\n",
        "def create_capex_trend_chart(df_metrics: pd.DataFrame) -> go.Figure:\n",
        "    \"\"\"\n",
        "    Create line chart showing CapEx intensity trends over time.\n",
        "\n",
        "    Args:\n",
        "        df_metrics: DataFrame with calculated metrics\n",
        "\n",
        "    Returns:\n",
        "        Plotly Figure object\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for ticker in COMPANY_ORDER:\n",
        "        company_data = df_metrics[df_metrics['ticker'] == ticker].sort_values('fiscal_year')\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=company_data['fiscal_year'],\n",
        "            y=company_data['capex_intensity'] * 100,  # Convert to percentage\n",
        "            name=COMPANIES[ticker]['name'],\n",
        "            line=dict(color=COMPANIES[ticker]['color'], width=2.5),\n",
        "            mode='lines+markers',\n",
        "            marker=dict(size=8)\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=dict(\n",
        "            text='CapEx Intensity Trend (% of Revenue)',\n",
        "            font=dict(size=18)\n",
        "        ),\n",
        "        xaxis_title='Fiscal Year',\n",
        "        yaxis_title='CapEx / Revenue (%)',\n",
        "        template=CHART_TEMPLATE,\n",
        "        height=450,\n",
        "        width=850,\n",
        "        legend=dict(\n",
        "            orientation='h',\n",
        "            yanchor='bottom',\n",
        "            y=-0.25,\n",
        "            xanchor='center',\n",
        "            x=0.5\n",
        "        ),\n",
        "        xaxis=dict(tickmode='array', tickvals=FISCAL_YEARS),\n",
        "        yaxis=dict(ticksuffix='%')\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# %%\n",
        "# 9.4 Monetization Velocity Quadrant (CORRECTED)\n",
        "# -----------------------------------------------------------------------------\n",
        "def create_velocity_quadrant(df_metrics: pd.DataFrame, year: int) -> go.Figure:\n",
        "    \"\"\"\n",
        "    Create quadrant chart: CapEx Intensity vs. Revenue Yield.\n",
        "    Visualizes the Monetization Velocity concept with smart label positioning.\n",
        "    \"\"\"\n",
        "    df_year = df_metrics[df_metrics['fiscal_year'] == year].copy()\n",
        "    df_year = df_year.dropna(subset=['capex_intensity', 'revenue_yield_on_capex'])\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Custom label positions to avoid overlap\n",
        "    label_adjustments = {\n",
        "        'NVDA': (0, 3, 'top center'),\n",
        "        'AAPL': (0, 1.5, 'top center'),\n",
        "        'TSLA': (-1.5, 0, 'middle left'),\n",
        "        'AMZN': (0, -1.5, 'bottom center'),\n",
        "        'GOOGL': (1.5, 0, 'middle right'),\n",
        "        'MSFT': (0, 1.5, 'top center'),\n",
        "        'META': (0, -1.5, 'bottom center')\n",
        "    }\n",
        "\n",
        "    for _, row in df_year.iterrows():\n",
        "        ticker = row['ticker']\n",
        "        x_val = row['capex_intensity'] * 100\n",
        "        y_val = row['revenue_yield_on_capex']\n",
        "\n",
        "        x_offset, y_offset, text_pos = label_adjustments.get(ticker, (0, 0, 'top center'))\n",
        "\n",
        "        # Add marker\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[x_val],\n",
        "            y=[y_val],\n",
        "            mode='markers',\n",
        "            name=COMPANIES[ticker]['name'],\n",
        "            marker=dict(\n",
        "                size=30,\n",
        "                color=COMPANIES[ticker]['color'],\n",
        "                line=dict(width=2, color='white')\n",
        "            ),\n",
        "            hovertemplate=f\"<b>{COMPANIES[ticker]['name']}</b><br>\" +\n",
        "                          f\"CapEx Intensity: {x_val:.1f}%<br>\" +\n",
        "                          f\"Revenue Yield: {y_val:.1f}x<extra></extra>\"\n",
        "        ))\n",
        "\n",
        "        # Add label with offset\n",
        "        fig.add_annotation(\n",
        "            x=x_val,\n",
        "            y=y_val + y_offset,\n",
        "            text=f\"<b>{COMPANIES[ticker]['name']}</b>\",\n",
        "            showarrow=True if y_offset != 0 or x_offset != 0 else False,\n",
        "            arrowhead=0,\n",
        "            arrowsize=1,\n",
        "            arrowwidth=1,\n",
        "            arrowcolor='gray',\n",
        "            ax=x_offset * 10,\n",
        "            ay=-y_offset * 10 if y_offset > 0 else -y_offset * 10,\n",
        "            font=dict(size=11, color='black'),\n",
        "            align='center'\n",
        "        )\n",
        "\n",
        "    # Add quadrant lines\n",
        "    median_intensity = df_year['capex_intensity'].median() * 100\n",
        "    median_yield = df_year['revenue_yield_on_capex'].median()\n",
        "\n",
        "    fig.add_hline(y=median_yield, line_dash='dash', line_color='gray', opacity=0.5)\n",
        "    fig.add_vline(x=median_intensity, line_dash='dash', line_color='gray', opacity=0.5)\n",
        "\n",
        "    # Add quadrant labels\n",
        "    fig.add_annotation(x=0.02, y=0.98, xref='paper', yref='paper',\n",
        "                       text='<b>Efficient</b><br><span style=\"font-size:10px\">Low Investment, High Return</span>',\n",
        "                       showarrow=False, font=dict(size=11, color='green'),\n",
        "                       align='left', xanchor='left', yanchor='top')\n",
        "    fig.add_annotation(x=0.98, y=0.98, xref='paper', yref='paper',\n",
        "                       text='<b>Scaling</b><br><span style=\"font-size:10px\">High Investment, High Return</span>',\n",
        "                       showarrow=False, font=dict(size=11, color='blue'),\n",
        "                       align='right', xanchor='right', yanchor='top')\n",
        "    fig.add_annotation(x=0.02, y=0.02, xref='paper', yref='paper',\n",
        "                       text='<b>Stagnant</b><br><span style=\"font-size:10px\">Low Investment, Low Return</span>',\n",
        "                       showarrow=False, font=dict(size=11, color='gray'),\n",
        "                       align='left', xanchor='left', yanchor='bottom')\n",
        "    fig.add_annotation(x=0.98, y=0.02, xref='paper', yref='paper',\n",
        "                       text='<b>Investing</b><br><span style=\"font-size:10px\">High Investment, Low Return</span>',\n",
        "                       showarrow=False, font=dict(size=11, color='orange'),\n",
        "                       align='right', xanchor='right', yanchor='bottom')\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=dict(\n",
        "            text=f'Monetization Velocity Quadrant (FY{year})',\n",
        "            font=dict(size=18)\n",
        "        ),\n",
        "        xaxis_title='CapEx Intensity (% of Revenue)',\n",
        "        yaxis_title='Revenue Yield on CapEx ($/$)',\n",
        "        template=CHART_TEMPLATE,\n",
        "        height=600,\n",
        "        width=850,\n",
        "        showlegend=False,\n",
        "        xaxis=dict(\n",
        "            ticksuffix='%',\n",
        "            range=[0, 25],\n",
        "            dtick=5\n",
        "        ),\n",
        "        yaxis=dict(\n",
        "            range=[-2, 55],\n",
        "            dtick=10\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# %%\n",
        "# 9.5 AI Segment Profitability Comparison\n",
        "# -----------------------------------------------------------------------------\n",
        "def create_segment_margin_chart(df_ai_segments: pd.DataFrame, year: int) -> go.Figure:\n",
        "    \"\"\"\n",
        "    Bar chart comparing AI-primary segment operating margins.\n",
        "\n",
        "    Args:\n",
        "        df_ai_segments: DataFrame with AI-primary segment data\n",
        "        year: Fiscal year to display\n",
        "\n",
        "    Returns:\n",
        "        Plotly Figure object\n",
        "    \"\"\"\n",
        "    df_year = df_ai_segments[df_ai_segments['fiscal_year'] == year].copy()\n",
        "    df_year = df_year.sort_values('segment_operating_margin', ascending=True)\n",
        "\n",
        "    colors = [COMPANIES[t]['color'] for t in df_year['ticker']]\n",
        "    labels = [f\"{COMPANIES[t]['name']}<br>({s})\"\n",
        "              for t, s in zip(df_year['ticker'], df_year['segment_name'])]\n",
        "\n",
        "    fig = go.Figure(go.Bar(\n",
        "        x=df_year['segment_operating_margin'] * 100,\n",
        "        y=labels,\n",
        "        orientation='h',\n",
        "        marker_color=colors,\n",
        "        text=[f\"{m:.1f}%\" for m in df_year['segment_operating_margin'] * 100],\n",
        "        textposition='outside',\n",
        "        textfont=dict(size=11)\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=dict(\n",
        "            text=f'AI-Primary Segment Operating Margins (FY{year})',\n",
        "            font=dict(size=18)\n",
        "        ),\n",
        "        xaxis_title='Operating Margin (%)',\n",
        "        yaxis_title='',\n",
        "        template=CHART_TEMPLATE,\n",
        "        height=450,\n",
        "        width=750,\n",
        "        xaxis=dict(ticksuffix='%', range=[-100, 100]),\n",
        "        margin=dict(l=180)\n",
        "    )\n",
        "\n",
        "    # Add vertical line at 0%\n",
        "    fig.add_vline(x=0, line_dash='solid', line_color='black', line_width=1)\n",
        "\n",
        "    return fig\n",
        "\n",
        "# %%\n",
        "# 9.6 Forward Guidance Comparison\n",
        "# -----------------------------------------------------------------------------\n",
        "def create_forward_guidance_chart(df_forward_analysis: pd.DataFrame) -> go.Figure:\n",
        "    \"\"\"\n",
        "    Bar chart comparing FY2025 CapEx guidance vs. FY2024 actual.\n",
        "\n",
        "    Args:\n",
        "        df_forward_analysis: DataFrame with forward guidance analysis\n",
        "\n",
        "    Returns:\n",
        "        Plotly Figure object\n",
        "    \"\"\"\n",
        "    df = df_forward_analysis.sort_values('guidance_vs_actual_pct', ascending=True)\n",
        "\n",
        "    colors = [COMPANIES[t]['color'] for t in df['ticker']]\n",
        "\n",
        "    fig = go.Figure(go.Bar(\n",
        "        x=df['guidance_vs_actual_pct'] * 100,\n",
        "        y=df['company'],\n",
        "        orientation='h',\n",
        "        marker_color=colors,\n",
        "        text=[f\"{p:+.0f}%\" for p in df['guidance_vs_actual_pct'] * 100],\n",
        "        textposition='outside',\n",
        "        textfont=dict(size=11)\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=dict(\n",
        "            text=f'FY{FORWARD_YEAR} CapEx Guidance vs. FY{CURRENT_YEAR} Actual',\n",
        "            font=dict(size=18)\n",
        "        ),\n",
        "        xaxis_title='Change (%)',\n",
        "        yaxis_title='',\n",
        "        template=CHART_TEMPLATE,\n",
        "        height=400,\n",
        "        width=700,\n",
        "        xaxis=dict(ticksuffix='%'),\n",
        "        margin=dict(l=100)\n",
        "    )\n",
        "\n",
        "    # Add vertical line at 0%\n",
        "    fig.add_vline(x=0, line_dash='solid', line_color='black', line_width=1)\n",
        "\n",
        "    return fig\n",
        "\n",
        "# %%\n",
        "# 9.7 Generate All Visualizations\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"GENERATING VISUALIZATIONS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Store figures for export\n",
        "figures = {}\n",
        "\n",
        "if df_final_scores is not None:\n",
        "    print(\"\\n✓ Creating scorecard heatmap...\")\n",
        "    fig_heatmap = create_scorecard_heatmap(df_final_scores, CURRENT_YEAR)\n",
        "    figures['scorecard_heatmap'] = fig_heatmap\n",
        "    fig_heatmap.show()\n",
        "\n",
        "    print(\"✓ Creating radar chart...\")\n",
        "    fig_radar = create_radar_chart(df_final_scores, CURRENT_YEAR)\n",
        "    figures['radar_chart'] = fig_radar\n",
        "    fig_radar.show()\n",
        "\n",
        "if df_metrics is not None:\n",
        "    print(\"✓ Creating CapEx trend chart...\")\n",
        "    fig_trend = create_capex_trend_chart(df_metrics)\n",
        "    figures['capex_trend'] = fig_trend\n",
        "    fig_trend.show()\n",
        "\n",
        "    print(\"✓ Creating velocity quadrant...\")\n",
        "    fig_quadrant = create_velocity_quadrant(df_metrics, CURRENT_YEAR)\n",
        "    figures['velocity_quadrant'] = fig_quadrant\n",
        "    fig_quadrant.show()\n",
        "\n",
        "if df_ai_segments is not None and len(df_ai_segments) > 0:\n",
        "    print(\"✓ Creating segment margin chart...\")\n",
        "    fig_segments = create_segment_margin_chart(df_ai_segments, CURRENT_YEAR)\n",
        "    figures['segment_margins'] = fig_segments\n",
        "    fig_segments.show()\n",
        "\n",
        "if df_forward_analysis is not None:\n",
        "    print(\"✓ Creating forward guidance chart...\")\n",
        "    fig_forward = create_forward_guidance_chart(df_forward_analysis)\n",
        "    figures['forward_guidance'] = fig_forward\n",
        "    fig_forward.show()\n",
        "\n",
        "print(f\"\\n✓ Generated {len(figures)} visualizations\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 10: EXECUTIVE SUMMARY GENERATOR\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 10: Executive Summary Generator\n",
        "\n",
        "Auto-generate key findings text from model outputs.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 10.1 Generate Executive Summary\n",
        "# -----------------------------------------------------------------------------\n",
        "def generate_executive_summary(df_scores: pd.DataFrame,\n",
        "                               df_metrics: pd.DataFrame,\n",
        "                               df_forward: pd.DataFrame = None,\n",
        "                               year: int = CURRENT_YEAR) -> str:\n",
        "    \"\"\"\n",
        "    Generate executive summary text from model outputs.\n",
        "\n",
        "    Args:\n",
        "        df_scores: DataFrame with final scores\n",
        "        df_metrics: DataFrame with calculated metrics\n",
        "        df_forward: DataFrame with forward guidance (optional)\n",
        "        year: Fiscal year for analysis\n",
        "\n",
        "    Returns:\n",
        "        Markdown-formatted summary string\n",
        "    \"\"\"\n",
        "    df_year = df_scores[df_scores['fiscal_year'] == year].sort_values(\n",
        "        'overall_score', ascending=False\n",
        "    )\n",
        "\n",
        "    # Top and bottom performers\n",
        "    top_performer = df_year.iloc[0]\n",
        "    bottom_performer = df_year.iloc[-1]\n",
        "\n",
        "    # Classification counts\n",
        "    classifications = df_year['classification'].value_counts().to_dict()\n",
        "\n",
        "    # Score spread\n",
        "    score_spread = top_performer['overall_score'] - bottom_performer['overall_score']\n",
        "\n",
        "    # Build summary\n",
        "    summary = f\"\"\"\n",
        "# Executive Summary: Capital Allocation Efficiency Scorecard\n",
        "\n",
        "**Analysis Period**: FY{year}\n",
        "**Companies Analyzed**: {len(df_year)} (Magnificent Seven)\n",
        "**Generated**: {datetime.now().strftime('%Y-%m-%d')}\n",
        "\n",
        "---\n",
        "\n",
        "## Key Finding\n",
        "\n",
        "Among the Magnificent Seven, **{COMPANIES[top_performer['ticker']]['name']}** demonstrates\n",
        "the highest capital allocation efficiency with an overall score of **{top_performer['overall_score']:.1f}/10**,\n",
        "while **{COMPANIES[bottom_performer['ticker']]['name']}** scores lowest at **{bottom_performer['overall_score']:.1f}/10**.\n",
        "\n",
        "The **{score_spread:.1f}-point spread** between highest and lowest scores indicates meaningful\n",
        "differentiation in capital productivity across the peer group.\n",
        "\n",
        "---\n",
        "\n",
        "## Classification Distribution\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    for classification in ['Capital Efficient', 'Capital Intensive', 'Capital Dependent']:\n",
        "        if classification in classifications:\n",
        "            count = classifications[classification]\n",
        "            companies_in_class = df_year[df_year['classification'] == classification]['ticker'].tolist()\n",
        "            company_names = [COMPANIES[t]['name'] for t in companies_in_class]\n",
        "            summary += f\"**{classification}** ({count}): {', '.join(company_names)}\\n\\n\"\n",
        "\n",
        "    # Dimension leaders\n",
        "    summary += \"\"\"---\n",
        "\n",
        "## Dimension Leaders\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    dimensions = {\n",
        "        'conversion_efficiency_score': 'Conversion Efficiency',\n",
        "        'return_quality_score': 'Return Quality',\n",
        "        'sustainability_risk_score': 'Sustainability & Risk',\n",
        "        'capital_deployment_score': 'Capital Deployment'\n",
        "    }\n",
        "\n",
        "    for col, name in dimensions.items():\n",
        "        if col in df_year.columns:\n",
        "            leader_idx = df_year[col].idxmax()\n",
        "            leader_ticker = df_year.loc[leader_idx, 'ticker']\n",
        "            leader_score = df_year.loc[leader_idx, col]\n",
        "            summary += f\"- **{name}**: {COMPANIES[leader_ticker]['name']} ({leader_score:.1f})\\n\"\n",
        "\n",
        "    # Strategic implications\n",
        "    summary += \"\"\"\n",
        "---\n",
        "\n",
        "## Strategic Implications\n",
        "\n",
        "1. **High Conversion Efficiency** companies are successfully translating CapEx into\n",
        "   near-term revenue growth, validating their AI investment thesis.\n",
        "\n",
        "2. **Companies in the \"Capital Intensive\" tier** face investor scrutiny on return timing.\n",
        "   Monitor for margin improvement in coming quarters.\n",
        "\n",
        "3. **Low Sustainability scores** indicate potential financial strain if AI investment\n",
        "   continues at current pace without corresponding revenue acceleration.\n",
        "\n",
        "---\n",
        "\n",
        "## Methodology Note\n",
        "\n",
        "This scorecard uses percentile ranking within the Magnificent Seven peer group.\n",
        "Scores reflect relative positioning, not absolute thresholds. A company scoring\n",
        "5.0 represents median performance among these seven technology leaders.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Add forward guidance section if available\n",
        "    if df_forward is not None and len(df_forward) > 0:\n",
        "        accelerating = df_forward[df_forward['investment_trajectory'] == 'Accelerating']['company'].tolist()\n",
        "        decelerating = df_forward[df_forward['investment_trajectory'] == 'Decelerating']['company'].tolist()\n",
        "\n",
        "        summary += f\"\"\"---\n",
        "\n",
        "## Forward Outlook (FY{FORWARD_YEAR})\n",
        "\n",
        "Based on disclosed CapEx guidance:\n",
        "\n",
        "\"\"\"\n",
        "        if accelerating:\n",
        "            summary += f\"- **Accelerating Investment**: {', '.join(accelerating)}\\n\"\n",
        "        if decelerating:\n",
        "            summary += f\"- **Decelerating Investment**: {', '.join(decelerating)}\\n\"\n",
        "\n",
        "        summary += \"\\nMonitor Q1-Q2 earnings for guidance revisions as AI demand signals evolve.\\n\"\n",
        "\n",
        "    return summary\n",
        "\n",
        "# %%\n",
        "# 10.2 Generate and Display Summary\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"EXECUTIVE SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if df_final_scores is not None and df_metrics is not None:\n",
        "    executive_summary = generate_executive_summary(\n",
        "        df_final_scores,\n",
        "        df_metrics,\n",
        "        df_forward_scored if 'df_forward_scored' in dir() else None,\n",
        "        CURRENT_YEAR\n",
        "    )\n",
        "\n",
        "    from IPython.display import Markdown\n",
        "    display(Markdown(executive_summary))\n",
        "else:\n",
        "    print(\"\\n✗ Cannot generate summary: required data not available\")\n",
        "    executive_summary = None\n",
        "\n",
        "!pip install -U kaleido -q\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 11: EXPORT FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 11: Export Functions\n",
        "\n",
        "Save outputs for GitHub repository and external use.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 11.1 Export Data to CSV\n",
        "# -----------------------------------------------------------------------------\n",
        "def export_data_to_csv(output_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Export all DataFrames to CSV files.\n",
        "\n",
        "    Args:\n",
        "        output_path: Directory path for output files\n",
        "\n",
        "    Returns:\n",
        "        List of exported file paths\n",
        "    \"\"\"\n",
        "    exported_files = []\n",
        "\n",
        "    exports = {\n",
        "        'consolidated_financials': df_consolidated,\n",
        "        'calculated_metrics': df_metrics if 'df_metrics' in dir() else None,\n",
        "        'final_scores': df_final_scores if 'df_final_scores' in dir() else None,\n",
        "        'segment_metrics': df_segment_metrics if 'df_segment_metrics' in dir() else None,\n",
        "        'ai_primary_segments': df_ai_segments if 'df_ai_segments' in dir() else None,\n",
        "        'forward_guidance_analysis': df_forward_scored if 'df_forward_scored' in dir() else None\n",
        "    }\n",
        "\n",
        "    for name, df in exports.items():\n",
        "        if df is not None and len(df) > 0:\n",
        "            filepath = f\"{output_path}{name}.csv\"\n",
        "            df.to_csv(filepath, index=False)\n",
        "            exported_files.append(filepath)\n",
        "            print(f\"✓ Exported: {name}.csv\")\n",
        "\n",
        "    return exported_files\n",
        "\n",
        "# %%\n",
        "# 11.2 Export Visualizations\n",
        "# -----------------------------------------------------------------------------\n",
        "def export_visualizations(output_path: str, figures_dict: dict) -> List[str]:\n",
        "    \"\"\"\n",
        "    Export all figures as PNG and HTML files.\n",
        "\n",
        "    Args:\n",
        "        output_path: Directory path for output files\n",
        "        figures_dict: Dictionary of figure name -> Plotly Figure\n",
        "\n",
        "    Returns:\n",
        "        List of exported file paths\n",
        "    \"\"\"\n",
        "    exported_files = []\n",
        "\n",
        "    for name, fig in figures_dict.items():\n",
        "        if fig is not None:\n",
        "            try:\n",
        "                # Export as PNG\n",
        "                png_path = f\"{output_path}{name}.png\"\n",
        "                fig.write_image(png_path, scale=2)\n",
        "                exported_files.append(png_path)\n",
        "\n",
        "                # Export as interactive HTML\n",
        "                html_path = f\"{output_path}{name}.html\"\n",
        "                fig.write_html(html_path)\n",
        "                exported_files.append(html_path)\n",
        "\n",
        "                print(f\"✓ Exported: {name}.png and {name}.html\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠ Could not export {name}: {e}\")\n",
        "\n",
        "    return exported_files\n",
        "\n",
        "# %%\n",
        "# 11.3 Export Executive Summary\n",
        "# -----------------------------------------------------------------------------\n",
        "def export_summary(output_path: str, summary_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Export executive summary as Markdown file.\n",
        "\n",
        "    Args:\n",
        "        output_path: Directory path for output file\n",
        "        summary_text: Markdown-formatted summary\n",
        "\n",
        "    Returns:\n",
        "        Path to exported file\n",
        "    \"\"\"\n",
        "    filepath = f\"{output_path}executive_summary.md\"\n",
        "\n",
        "    with open(filepath, 'w') as f:\n",
        "        f.write(summary_text)\n",
        "\n",
        "    print(f\"✓ Exported: executive_summary.md\")\n",
        "    return filepath\n",
        "\n",
        "# %%\n",
        "# 11.4 Execute All Exports\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPORTING OUTPUTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Export data\n",
        "print(\"\\nExporting data files...\")\n",
        "export_data_to_csv(OUTPUT_PATH)\n",
        "\n",
        "# Export visualizations\n",
        "if 'figures' in dir() and len(figures) > 0:\n",
        "    print(\"\\nExporting visualizations...\")\n",
        "    export_visualizations(OUTPUT_PATH, figures)\n",
        "\n",
        "# Export executive summary\n",
        "if 'executive_summary' in dir() and executive_summary is not None:\n",
        "    print(\"\\nExporting executive summary...\")\n",
        "    export_summary(OUTPUT_PATH, executive_summary)\n",
        "\n",
        "print(f\"\\n{'=' * 70}\")\n",
        "print(f\"✓ All exports complete\")\n",
        "print(f\"  Output location: {OUTPUT_PATH}\")\n",
        "print(f\"{'=' * 70}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 12: MODEL REFRESH UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## Section 12: Model Refresh Utilities\n",
        "\n",
        "Streamline updates when new 10-K filings become available.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# 12.1 Data Refresh Checklist Generator\n",
        "# -----------------------------------------------------------------------------\n",
        "def generate_refresh_checklist(target_year: int) -> str:\n",
        "    \"\"\"\n",
        "    Generate checklist for updating model with new fiscal year data.\n",
        "\n",
        "    Args:\n",
        "        target_year: The new fiscal year to add\n",
        "\n",
        "    Returns:\n",
        "        Markdown-formatted checklist\n",
        "    \"\"\"\n",
        "    checklist = f\"\"\"\n",
        "# Model Refresh Checklist: FY{target_year}\n",
        "\n",
        "## Expected Filing Dates\n",
        "\n",
        "| Company | Fiscal Year End | Expected 10-K Filing |\n",
        "|---------|-----------------|---------------------|\n",
        "\"\"\"\n",
        "\n",
        "    filing_dates = {\n",
        "        'AAPL': 'Late October',\n",
        "        'MSFT': 'Late July',\n",
        "        'GOOGL': 'Early February',\n",
        "        'AMZN': 'Early February',\n",
        "        'META': 'Early February',\n",
        "        'NVDA': 'Late February',\n",
        "        'TSLA': 'Late January'\n",
        "    }\n",
        "\n",
        "    for ticker, config in COMPANIES.items():\n",
        "        checklist += f\"| {config['name']} | {config['fy_end']} | {filing_dates[ticker]} |\\n\"\n",
        "\n",
        "    checklist += f\"\"\"\n",
        "---\n",
        "\n",
        "## Data Collection Tasks\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    for ticker, config in COMPANIES.items():\n",
        "        checklist += f\"\"\"\n",
        "### {config['name']} ({ticker})\n",
        "\n",
        "- [ ] Download 10-K filing from SEC EDGAR\n",
        "- [ ] Extract consolidated financial data\n",
        "- [ ] Extract segment data (if applicable)\n",
        "- [ ] Update forward guidance from latest earnings call\n",
        "- [ ] Verify purchase obligations from Notes\n",
        "- [ ] Cross-check against earnings release figures\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    checklist += f\"\"\"\n",
        "---\n",
        "\n",
        "## Configuration Updates\n",
        "\n",
        "After collecting all data:\n",
        "\n",
        "1. [ ] Update `FISCAL_YEARS` list: `[{target_year-2}, {target_year-1}, {target_year}]`\n",
        "2. [ ] Update `CURRENT_YEAR`: `{target_year}`\n",
        "3. [ ] Update `FORWARD_YEAR`: `{target_year + 1}`\n",
        "4. [ ] Set `USE_SYNTHETIC_DATA = False`\n",
        "\n",
        "---\n",
        "\n",
        "## Validation Steps\n",
        "\n",
        "- [ ] Run data completeness check (Section 4)\n",
        "- [ ] Review reasonableness check results\n",
        "- [ ] Investigate any YoY change flags\n",
        "- [ ] Verify segment data reconciles to consolidated\n",
        "\n",
        "---\n",
        "\n",
        "## Output Updates\n",
        "\n",
        "- [ ] Regenerate all visualizations\n",
        "- [ ] Update executive summary\n",
        "- [ ] Export new CSV files\n",
        "- [ ] Commit changes to GitHub repository\n",
        "- [ ] Update README with new findings\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    return checklist\n",
        "\n",
        "# %%\n",
        "# 12.2 Quick Refresh Function\n",
        "# -----------------------------------------------------------------------------\n",
        "def refresh_model_config(new_year: int):\n",
        "    \"\"\"\n",
        "    Quick configuration refresh for new fiscal year.\n",
        "\n",
        "    Note: This updates global variables. Re-run Sections 3-11 after calling.\n",
        "\n",
        "    Args:\n",
        "        new_year: The new current fiscal year\n",
        "    \"\"\"\n",
        "    global CURRENT_YEAR, FORWARD_YEAR, FISCAL_YEARS\n",
        "\n",
        "    # Update configuration\n",
        "    FISCAL_YEARS = [new_year - 2, new_year - 1, new_year]\n",
        "    CURRENT_YEAR = new_year\n",
        "    FORWARD_YEAR = new_year + 1\n",
        "\n",
        "    print(f\"{'=' * 70}\")\n",
        "    print(\"CONFIGURATION UPDATED\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "    print(f\"\\n  Analysis period: {FISCAL_YEARS}\")\n",
        "    print(f\"  Current year: FY{CURRENT_YEAR}\")\n",
        "    print(f\"  Forward year: FY{FORWARD_YEAR}\")\n",
        "    print(f\"\\n⚠️  Re-run Sections 3-11 to complete the refresh.\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "\n",
        "# %%\n",
        "# 12.3 Display Refresh Checklist\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"MODEL REFRESH UTILITIES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Generate checklist for next refresh cycle\n",
        "next_year = CURRENT_YEAR + 1\n",
        "checklist = generate_refresh_checklist(next_year)\n",
        "\n",
        "print(f\"\\nRefresh checklist generated for FY{next_year}\")\n",
        "print(\"Uncomment the line below to display the full checklist:\")\n",
        "print(\"# display(Markdown(checklist))\")\n",
        "\n",
        "# To refresh for a new year, uncomment and run:\n",
        "# refresh_model_config(2025)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"NOTEBOOK EXECUTION COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if USE_SYNTHETIC_DATA:\n",
        "    print(\"\\n⚠️  REMINDER: This analysis used SYNTHETIC data.\")\n",
        "    print(\"   Set USE_SYNTHETIC_DATA = False and provide real SEC data\")\n",
        "    print(\"   before using results for decision-making.\")"
      ],
      "metadata": {
        "id": "d-mv3AXFP4JB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}